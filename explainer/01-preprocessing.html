<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Module 01: Text Preprocessing - NLP Course</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        :root {
            --bg: #0a0a0f;
            --surface: #12121a;
            --card: #1a1a2e;
            --border: #2a2a3e;
            --accent: #6c63ff;
            --accent2: #00d2ff;
            --accent3: #ff6b6b;
            --text: #e0e0e8;
            --muted: #8888a0;
            --code-bg: #0d1117;
        }

        body {
            font-family: Inter, system-ui, -apple-system, sans-serif;
            background: var(--bg);
            color: var(--text);
            line-height: 1.6;
            overflow-x: hidden;
        }

        /* Navbar */
        nav {
            position: sticky;
            top: 0;
            z-index: 100;
            background: rgba(10, 10, 15, 0.95);
            backdrop-filter: blur(10px);
            border-bottom: 1px solid var(--border);
            padding: 1rem 2rem;
            display: flex;
            align-items: center;
            gap: 2rem;
        }

        nav a {
            display: flex;
            align-items: center;
            gap: 0.5rem;
            color: var(--text);
            text-decoration: none;
            font-weight: 500;
            transition: color 0.3s;
        }

        nav a:hover {
            color: var(--accent);
        }

        nav h1 {
            margin-left: auto;
            font-size: 1.2rem;
            font-weight: 600;
        }

        /* Main content */
        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 2rem;
        }

        section {
            margin-bottom: 4rem;
            opacity: 0;
            transform: translateY(20px);
            animation: fadeInUp 0.6s ease-out forwards;
        }

        section:nth-child(1) { animation-delay: 0s; }
        section:nth-child(2) { animation-delay: 0.1s; }
        section:nth-child(3) { animation-delay: 0.2s; }
        section:nth-child(4) { animation-delay: 0.3s; }
        section:nth-child(5) { animation-delay: 0.4s; }
        section:nth-child(6) { animation-delay: 0.5s; }
        section:nth-child(7) { animation-delay: 0.6s; }
        section:nth-child(8) { animation-delay: 0.7s; }
        section:nth-child(9) { animation-delay: 0.8s; }
        section:nth-child(10) { animation-delay: 0.9s; }

        @keyframes fadeInUp {
            from {
                opacity: 0;
                transform: translateY(20px);
            }
            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        /* Section animations on scroll */
        section.scroll-in {
            animation: fadeInUp 0.8s ease-out forwards !important;
        }

        h2 {
            font-size: 2.5rem;
            margin-bottom: 1rem;
            background: linear-gradient(135deg, var(--accent) 0%, var(--accent2) 100%);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
        }

        h3 {
            font-size: 1.5rem;
            margin-top: 1.5rem;
            margin-bottom: 1rem;
            color: var(--accent);
        }

        p {
            color: var(--text);
            margin-bottom: 1rem;
            font-size: 1.05rem;
        }

        /* Hero section */
        .hero {
            text-align: center;
            padding: 4rem 2rem;
            background: linear-gradient(135deg, rgba(108, 99, 255, 0.1) 0%, rgba(0, 210, 255, 0.1) 100%);
            border-radius: 12px;
            border: 1px solid var(--border);
            margin-bottom: 3rem;
        }

        .hero h2 {
            font-size: 3.5rem;
            margin-bottom: 1rem;
        }

        .hero .subtitle {
            font-size: 1.3rem;
            color: var(--muted);
            margin-bottom: 1.5rem;
        }

        .hero .time {
            display: inline-block;
            background: var(--card);
            padding: 0.5rem 1.5rem;
            border-radius: 50px;
            font-size: 0.95rem;
            color: var(--accent);
            border: 1px solid var(--accent);
        }

        /* Cards */
        .card {
            background: var(--card);
            border: 1px solid var(--border);
            border-radius: 12px;
            padding: 2rem;
            margin-bottom: 1.5rem;
            transition: all 0.3s;
        }

        .card:hover {
            border-color: var(--accent);
            box-shadow: 0 0 20px rgba(108, 99, 255, 0.2);
        }

        /* Pipeline diagram */
        .pipeline-svg {
            width: 100%;
            height: auto;
            margin: 2rem 0;
        }

        /* Input boxes */
        input[type="text"],
        textarea {
            width: 100%;
            padding: 1rem;
            background: var(--surface);
            border: 1px solid var(--border);
            border-radius: 8px;
            color: var(--text);
            font-family: inherit;
            font-size: 1rem;
            margin-bottom: 1rem;
            transition: border-color 0.3s;
        }

        input[type="text"]:focus,
        textarea:focus {
            outline: none;
            border-color: var(--accent);
            box-shadow: 0 0 10px rgba(108, 99, 255, 0.3);
        }

        /* Buttons */
        button {
            padding: 0.75rem 1.5rem;
            background: var(--accent);
            border: none;
            border-radius: 8px;
            color: white;
            font-weight: 600;
            cursor: pointer;
            transition: all 0.3s;
            margin-right: 0.5rem;
            margin-bottom: 0.5rem;
            font-size: 0.95rem;
        }

        button:hover {
            background: var(--accent);
            box-shadow: 0 0 20px rgba(108, 99, 255, 0.4);
            transform: translateY(-2px);
        }

        button.secondary {
            background: var(--card);
            border: 1px solid var(--border);
            color: var(--text);
        }

        button.secondary:hover {
            border-color: var(--accent2);
            box-shadow: 0 0 20px rgba(0, 210, 255, 0.3);
        }

        button.active {
            background: var(--accent2);
        }

        /* Token pills */
        .tokens {
            display: flex;
            flex-wrap: wrap;
            gap: 0.5rem;
            margin-top: 1.5rem;
            margin-bottom: 1.5rem;
        }

        .token {
            display: inline-block;
            background: var(--accent);
            color: white;
            padding: 0.5rem 1rem;
            border-radius: 20px;
            font-weight: 500;
            font-size: 0.9rem;
            animation: popIn 0.3s ease-out;
        }

        .token.stopword {
            background: var(--accent3);
        }

        .token.subword {
            background: var(--accent2);
        }

        @keyframes popIn {
            from {
                transform: scale(0.8);
                opacity: 0;
            }
            to {
                transform: scale(1);
                opacity: 1;
            }
        }

        /* Table */
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 1.5rem 0;
        }

        th {
            background: var(--accent);
            padding: 1rem;
            text-align: left;
            color: white;
            font-weight: 600;
        }

        td {
            padding: 1rem;
            border-bottom: 1px solid var(--border);
        }

        tr:hover {
            background: rgba(108, 99, 255, 0.1);
        }

        /* Code block */
        .code-block {
            background: var(--code-bg);
            border: 1px solid var(--border);
            border-radius: 8px;
            padding: 1.5rem;
            overflow-x: auto;
            margin: 1.5rem 0;
            font-family: 'Monaco', 'Courier New', monospace;
            font-size: 0.9rem;
            line-height: 1.5;
        }

        .code-block code {
            color: var(--text);
        }

        /* Syntax highlighting spans */
        .kw { color: #ff79c6; } /* Keywords */
        .str { color: #f1fa8c; } /* Strings */
        .com { color: #6272a4; } /* Comments */
        .func { color: #50fa7b; } /* Functions */
        .num { color: #bd93f9; } /* Numbers */
        .cls { color: #8be9fd; } /* Classes */

        /* Comparison grid */
        .comparison-grid {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 1.5rem;
            margin: 1.5rem 0;
        }

        .comparison-card {
            background: var(--card);
            border: 1px solid var(--border);
            border-radius: 8px;
            padding: 1.5rem;
            text-align: center;
        }

        .comparison-card h4 {
            color: var(--accent);
            margin-bottom: 1rem;
            font-size: 1.2rem;
        }

        .comparison-card .result {
            background: var(--surface);
            padding: 1rem;
            border-radius: 6px;
            font-family: monospace;
            font-weight: 500;
            color: var(--accent2);
            word-break: break-all;
        }

        /* Word count */
        .word-count {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 1rem;
            margin: 1rem 0;
        }

        .count-box {
            background: var(--surface);
            padding: 1rem;
            border-radius: 8px;
            text-align: center;
            border: 1px solid var(--border);
        }

        .count-number {
            font-size: 2rem;
            font-weight: 700;
            color: var(--accent2);
            margin-bottom: 0.5rem;
        }

        .count-label {
            color: var(--muted);
            font-size: 0.95rem;
        }

        /* Highlighted text */
        .highlighted {
            background: rgba(255, 107, 107, 0.3);
            color: var(--accent3);
            padding: 2px 4px;
            border-radius: 2px;
        }

        /* Decision tree */
        .decision-tree {
            background: var(--surface);
            padding: 2rem;
            border-radius: 8px;
            margin: 1.5rem 0;
            border: 1px solid var(--border);
            text-align: center;
        }

        .decision-tree svg {
            width: 100%;
            height: auto;
        }

        /* Pipeline stages */
        .pipeline-stage {
            background: var(--card);
            border: 1px solid var(--border);
            border-radius: 8px;
            padding: 1.5rem;
            margin-bottom: 1rem;
            cursor: pointer;
            transition: all 0.3s;
        }

        .pipeline-stage:hover {
            border-color: var(--accent2);
            box-shadow: 0 0 15px rgba(0, 210, 255, 0.2);
        }

        .pipeline-stage h4 {
            color: var(--accent2);
            margin-bottom: 0.5rem;
        }

        .pipeline-stage .input {
            background: var(--surface);
            padding: 0.75rem;
            border-radius: 4px;
            margin: 0.5rem 0;
            font-family: monospace;
            font-size: 0.9rem;
        }

        /* Footer */
        footer {
            margin-top: 4rem;
            padding-top: 2rem;
            border-top: 1px solid var(--border);
            display: flex;
            justify-content: space-between;
            align-items: center;
        }

        footer a {
            display: flex;
            align-items: center;
            gap: 0.5rem;
            color: var(--accent);
            text-decoration: none;
            font-weight: 600;
            transition: color 0.3s;
        }

        footer a:hover {
            color: var(--accent2);
        }

        /* Responsive */
        @media (max-width: 768px) {
            .container {
                padding: 1rem;
            }

            h2 {
                font-size: 2rem;
            }

            .comparison-grid {
                grid-template-columns: 1fr;
            }

            .hero h2 {
                font-size: 2rem;
            }

            nav {
                flex-direction: column;
                align-items: flex-start;
                gap: 1rem;
            }

            nav h1 {
                margin-left: 0;
                width: 100%;
            }
        }
    </style>
</head>
<body>
    <nav>
        <a href="index.html">← Back to Course</a>
        <h1>Module 01: Text Preprocessing</h1>
    </nav>

    <div class="container">
        <!-- Hero Section -->
        <section class="hero">
            <h2>Text Preprocessing</h2>
            <p class="subtitle">Transform raw text into clean, structured data ready for NLP models</p>
            <span class="time">⏱ Estimated time: ~20 minutes</span>
        </section>

        <!-- Why Preprocess -->
        <section>
            <h2>Why Preprocess?</h2>
            <p>Raw text is messy, inconsistent, and full of noise. Preprocessing transforms it into a standardized format that NLP models can work with effectively.</p>

            <div class="card">
                <h3>The Challenge</h3>
                <p style="font-size: 1.1rem; color: var(--accent3);">
                    "Dr. Smith's email: Hi! I'm VERY excited about our NLP project... See you tomorrow!!!"
                </p>
                <p>Notice: capitalization, punctuation, abbreviations, extra spacing, repeated punctuation</p>
            </div>

            <h3>The Preprocessing Pipeline</h3>
            <svg class="pipeline-svg" viewBox="0 0 900 120" xmlns="http://www.w3.org/2000/svg">
                <!-- Raw text box -->
                <rect x="10" y="20" width="120" height="80" fill="#1a1a2e" stroke="#6c63ff" stroke-width="2" rx="4"/>
                <text x="70" y="65" text-anchor="middle" fill="#e0e0e8" font-weight="bold">Raw Text</text>

                <!-- Arrow -->
                <line x1="140" y1="60" x2="170" y2="60" stroke="#8888a0" stroke-width="2" marker-end="url(#arrowhead)"/>

                <!-- Lowercase box -->
                <rect x="180" y="20" width="120" height="80" fill="#1a1a2e" stroke="#6c63ff" stroke-width="2" rx="4"/>
                <text x="240" y="65" text-anchor="middle" fill="#e0e0e8" font-weight="bold">Lowercase</text>

                <!-- Arrow -->
                <line x1="310" y1="60" x2="340" y2="60" stroke="#8888a0" stroke-width="2" marker-end="url(#arrowhead)"/>

                <!-- Tokenize box -->
                <rect x="350" y="20" width="120" height="80" fill="#1a1a2e" stroke="#00d2ff" stroke-width="2" rx="4"/>
                <text x="410" y="65" text-anchor="middle" fill="#e0e0e8" font-weight="bold">Tokenize</text>

                <!-- Arrow -->
                <line x1="480" y1="60" x2="510" y2="60" stroke="#8888a0" stroke-width="2" marker-end="url(#arrowhead)"/>

                <!-- Remove Stop Words box -->
                <rect x="520" y="20" width="140" height="80" fill="#1a1a2e" stroke="#00d2ff" stroke-width="2" rx="4"/>
                <text x="590" y="65" text-anchor="middle" fill="#e0e0e8" font-weight="bold">Remove Stops</text>

                <!-- Arrow -->
                <line x1="670" y1="60" x2="700" y2="60" stroke="#8888a0" stroke-width="2" marker-end="url(#arrowhead)"/>

                <!-- Lemmatize box -->
                <rect x="710" y="20" width="120" height="80" fill="#1a1a2e" stroke="#ff6b6b" stroke-width="2" rx="4"/>
                <text x="770" y="65" text-anchor="middle" fill="#e0e0e8" font-weight="bold">Lemmatize</text>

                <!-- Arrow -->
                <line x1="840" y1="60" x2="870" y2="60" stroke="#8888a0" stroke-width="2" marker-end="url(#arrowhead)"/>

                <!-- Clean output box -->
                <rect x="880" y="20" width="20" height="80" fill="#50fa7b" stroke="#50fa7b" stroke-width="2" rx="2"/>

                <!-- Arrow marker definition -->
                <defs>
                    <marker id="arrowhead" markerWidth="10" markerHeight="10" refX="5" refY="5" orient="auto">
                        <polygon points="0 0, 10 5, 0 10" fill="#8888a0"/>
                    </marker>
                </defs>
            </svg>
        </section>

        <!-- Tokenization Interactive Demo -->
        <section>
            <h2>Tokenization: Breaking Text into Tokens</h2>
            <p>Tokenization splits text into individual words, sentences, or subword units. Choose a method and see how your text is broken down.</p>

            <div class="card">
                <h3>Try it Yourself</h3>
                <textarea id="tokenInput" placeholder="Enter a sentence... (e.g., 'Dr. Smith said: This project is amazing!')">Dr. Smith's email: I'm very excited about our NLP project... See you tomorrow!!!
                </textarea>

                <div style="display: flex; gap: 0.5rem; flex-wrap: wrap;">
                    <button onclick="tokenizeWords()">Word Tokenize</button>
                    <button onclick="tokenizeSentences()">Sentence Tokenize</button>
                    <button onclick="tokenizeSubword()">Subword (BPE)</button>
                </div>

                <div id="tokenOutput"></div>

                <div id="tokenExplanation" style="margin-top: 1.5rem; padding: 1rem; background: var(--surface); border-radius: 8px; display: none;">
                    <h4 style="color: var(--accent); margin-bottom: 0.5rem;">How This Works:</h4>
                    <p id="explanationText" style="margin: 0; font-size: 0.95rem;"></p>
                </div>
            </div>

            <h3>Understanding Each Method</h3>
            <div class="comparison-grid">
                <div class="comparison-card">
                    <h4>Word Tokenization</h4>
                    <p>Splits text on whitespace and punctuation. Best for most NLP tasks. Preserves punctuation as separate tokens.</p>
                </div>
                <div class="comparison-card">
                    <h4>Sentence Tokenization</h4>
                    <p>Identifies sentence boundaries using periods, question marks, exclamation marks. Useful for document-level analysis.</p>
                </div>
                <div class="comparison-card">
                    <h4>Subword Tokenization (BPE)</h4>
                    <p>Breaks words into character sequences. Handles unknown words and morphology. Used by modern transformers like BERT.</p>
                </div>
            </div>
        </section>

        <!-- Stemming vs Lemmatization -->
        <section>
            <h2>Stemming vs Lemmatization</h2>
            <p>Both reduce words to their base form, but use different approaches. Let's explore the differences.</p>

            <div class="card">
                <h3>Interactive Comparison</h3>
                <p style="color: var(--muted); margin-bottom: 1rem;">Type a word to see how it's processed:</p>
                <input type="text" id="wordInput" placeholder="e.g., running, studies, better, played" value="running">

                <div class="comparison-grid">
                    <div class="comparison-card">
                        <h4>Porter Stemmer</h4>
                        <p style="font-size: 0.9rem; color: var(--muted); margin-bottom: 0.5rem;">Rule-based, aggressive</p>
                        <div class="result" id="stemResult">run</div>
                    </div>
                    <div class="comparison-card">
                        <h4>WordNet Lemmatizer</h4>
                        <p style="font-size: 0.9rem; color: var(--muted); margin-bottom: 0.5rem;">Dictionary-based, conservative</p>
                        <div class="result" id="lemmaResult">running</div>
                    </div>
                </div>
            </div>

            <h3>Examples: Stemming vs Lemmatization</h3>
            <table>
                <thead>
                    <tr>
                        <th>Original Word</th>
                        <th>Stemmer Result</th>
                        <th>Lemmatizer Result</th>
                        <th>Notes</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>running</td>
                        <td>run</td>
                        <td>run</td>
                        <td>Both match</td>
                    </tr>
                    <tr>
                        <td>studies</td>
                        <td>studi</td>
                        <td>study</td>
                        <td>Stemmer creates non-word</td>
                    </tr>
                    <tr>
                        <td>better</td>
                        <td>better</td>
                        <td>good</td>
                        <td>Lemmatizer knows irregular form</td>
                    </tr>
                    <tr>
                        <td>played</td>
                        <td>play</td>
                        <td>play</td>
                        <td>Both match</td>
                    </tr>
                    <tr>
                        <td>agreed</td>
                        <td>agre</td>
                        <td>agree</td>
                        <td>Stemmer is too aggressive</td>
                    </tr>
                    <tr>
                        <td>organizational</td>
                        <td>organ</td>
                        <td>organizational</td>
                        <td>Stemmer overshoots, lemmatizer keeps it</td>
                    </tr>
                    <tr>
                        <td>happiness</td>
                        <td>happi</td>
                        <td>happiness</td>
                        <td>Lemmatizer preserves noun</td>
                    </tr>
                    <tr>
                        <td>eating</td>
                        <td>eat</td>
                        <td>eat</td>
                        <td>Both match</td>
                    </tr>
                </tbody>
            </table>

            <h3>Decision Tree: When to Use Which?</h3>
            <div class="decision-tree">
                <svg viewBox="0 0 800 300" xmlns="http://www.w3.org/2000/svg">
                    <!-- Root -->
                    <rect x="300" y="10" width="200" height="50" fill="#1a1a2e" stroke="#6c63ff" stroke-width="2" rx="4"/>
                    <text x="400" y="40" text-anchor="middle" fill="#e0e0e8" font-weight="bold" font-size="14">Do you need exact words?</text>

                    <!-- Left branch -->
                    <line x1="320" y1="60" x2="150" y2="100" stroke="#8888a0" stroke-width="2"/>
                    <text x="200" y="80" fill="#00d2ff" font-weight="bold" font-size="12">YES</text>
                    <rect x="50" y="100" width="200" height="50" fill="#1a1a2e" stroke="#00d2ff" stroke-width="2" rx="4"/>
                    <text x="150" y="135" text-anchor="middle" fill="#e0e0e8" font-weight="bold" font-size="14">Use Lemmatization</text>

                    <!-- Right branch -->
                    <line x1="480" y1="60" x2="650" y2="100" stroke="#8888a0" stroke-width="2"/>
                    <text x="600" y="80" fill="#ff6b6b" font-weight="bold" font-size="12">NO</text>
                    <rect x="550" y="100" width="200" height="50" fill="#1a1a2e" stroke="#ff6b6b" stroke-width="2" rx="4"/>
                    <text x="650" y="135" text-anchor="middle" fill="#e0e0e8" font-weight="bold" font-size="14">Use Stemming</text>

                    <!-- Left leaf -->
                    <rect x="20" y="180" width="260" height="100" fill="rgba(0, 210, 255, 0.1)" stroke="#00d2ff" stroke-width="2" rx="4"/>
                    <text x="150" y="205" text-anchor="middle" fill="#00d2ff" font-weight="bold" font-size="12">✓ Information retrieval</text>
                    <text x="150" y="225" text-anchor="middle" fill="#00d2ff" font-weight="bold" font-size="12">✓ Machine translation</text>
                    <text x="150" y="245" text-anchor="middle" fill="#00d2ff" font-weight="bold" font-size="12">✓ Question answering</text>
                    <text x="150" y="265" text-anchor="middle" fill="#00d2ff" font-weight="bold" font-size="12">✓ Semantic similarity</text>

                    <!-- Right leaf -->
                    <rect x="520" y="180" width="260" height="100" fill="rgba(255, 107, 107, 0.1)" stroke="#ff6b6b" stroke-width="2" rx="4"/>
                    <text x="650" y="205" text-anchor="middle" fill="#ff6b6b" font-weight="bold" font-size="12">✓ Text classification</text>
                    <text x="650" y="225" text-anchor="middle" fill="#ff6b6b" font-weight="bold" font-size="12">✓ Search engines</text>
                    <text x="650" y="245" text-anchor="middle" fill="#ff6b6b" font-weight="bold" font-size="12">✓ Dimensionality reduction</text>
                    <text x="650" y="265" text-anchor="middle" fill="#ff6b6b" font-weight="bold" font-size="12">✓ Clustering</text>
                </svg>
            </div>
        </section>

        <!-- Stop Word Removal -->
        <section>
            <h2>Stop Word Removal</h2>
            <p>Stop words are common words (the, is, and, etc.) that often don't carry important meaning. Removing them reduces noise and dimensionality.</p>

            <div class="card">
                <h3>Interactive Demo</h3>
                <p style="color: var(--muted); margin-bottom: 1rem;">Stop words are highlighted in red. Click the button to toggle their visibility:</p>

                <button id="toggleStopwords" class="secondary" onclick="toggleStopwords()">Remove Stop Words</button>

                <div id="stopwordText" style="margin-top: 1.5rem; padding: 1.5rem; background: var(--surface); border-radius: 8px; line-height: 2; font-size: 1.05rem;">
                    <!-- Filled by JavaScript -->
                </div>

                <div class="word-count">
                    <div class="count-box">
                        <div class="count-number" id="originalCount">20</div>
                        <div class="count-label">Original Words</div>
                    </div>
                    <div class="count-box">
                        <div class="count-number" id="cleanCount">12</div>
                        <div class="count-label">After Removal</div>
                    </div>
                </div>

                <div style="margin-top: 1rem; padding: 1rem; background: rgba(0, 210, 255, 0.1); border-radius: 8px; border: 1px solid rgba(0, 210, 255, 0.3);">
                    <p style="font-size: 0.95rem; margin: 0;"><strong>Important:</strong> Stop word removal is task-dependent. For sentiment analysis, "not" is crucial. For topic modeling, removing them is helpful. Always validate for your use case.</p>
                </div>
            </div>
        </section>

        <!-- Complete Pipeline Visualization -->
        <section>
            <h2>Complete Pipeline: Watch Your Text Transform</h2>
            <p>Enter any text and watch it flow through the entire preprocessing pipeline step-by-step.</p>

            <div class="card">
                <h3>Your Text</h3>
                <textarea id="pipelineInput" placeholder="Enter your text here...">I'm running through the forest very happily!
                </textarea>
                <button onclick="runPipeline()">Process Text</button>

                <div id="pipelineContainer" style="margin-top: 2rem;">
                    <!-- Filled by JavaScript -->
                </div>
            </div>
        </section>

        <!-- Python Code -->
        <section>
            <h2>Python Implementation</h2>
            <p>Here's a complete, working implementation using NLTK and spaCy:</p>

            <div class="code-block">
                <code>
<span class="com"># Install required libraries</span>
<span class="com"># pip install nltk spacy</span>
<span class="com"># python -m spacy download en_core_web_sm</span>

<span class="kw">import</span> nltk
<span class="kw">from</span> nltk.tokenize <span class="kw">import</span> word_tokenize, sent_tokenize
<span class="kw">from</span> nltk.stem <span class="kw">import</span> PorterStemmer, WordNetLemmatizer
<span class="kw">from</span> nltk.corpus <span class="kw">import</span> stopwords
<span class="kw">import</span> spacy
<span class="kw">import</span> re

<span class="com"># Download required NLTK data</span>
nltk.download(<span class="str">'punkt'</span>)
nltk.download(<span class="str">'wordnet'</span>)
nltk.download(<span class="str">'stopwords'</span>)

<span class="com"># Initialize tools</span>
stemmer = PorterStemmer()
lemmatizer = WordNetLemmatizer()
stop_words = set(stopwords.words(<span class="str">'english'</span>))
nlp = spacy.load(<span class="str">'en_core_web_sm'</span>)

<span class="kw">def</span> <span class="func">preprocess_text</span>(text):
    <span class="str">"""Complete text preprocessing pipeline"""</span>

    <span class="com"># 1. Convert to lowercase</span>
    text = text.lower()

    <span class="com"># 2. Remove special characters and extra whitespace</span>
    text = re.sub(r<span class="str">r'[^a-z0-9\s]'</span>, <span class="str">''</span>, text)
    text = re.sub(r<span class="str">r'\s+'</span>, <span class="str">' '</span>, text).strip()

    <span class="com"># 3. Word tokenization</span>
    tokens = word_tokenize(text)

    <span class="com"># 4. Remove stop words</span>
    tokens = [t <span class="kw">for</span> t <span class="kw">in</span> tokens <span class="kw">if</span> t <span class="kw">not</span> <span class="kw">in</span> stop_words]

    <span class="com"># 5. Lemmatization (NLTK method)</span>
    tokens = [lemmatizer.lemmatize(t) <span class="kw">for</span> t <span class="kw">in</span> tokens]

    <span class="kw">return</span> tokens

<span class="kw">def</span> <span class="func">preprocess_with_spacy</span>(text):
    <span class="str">"""Using spaCy for preprocessing"""</span>

    <span class="com"># spaCy handles tokenization, lemmatization, POS tagging</span>
    doc = nlp(text.lower())

    <span class="com"># Filter out stopwords and non-alphabetic tokens</span>
    tokens = [token.lemma_ <span class="kw">for</span> token <span class="kw">in</span> doc
              <span class="kw">if</span> <span class="kw">not</span> token.is_stop <span class="kw">and</span> token.is_alpha]

    <span class="kw">return</span> tokens

<span class="com"># Example usage</span>
text = <span class="str">"I'm running through the forest very happily!"</span>

print(<span class="str">"Original:"</span>, text)
print(<span class="str">"Preprocessed (NLTK):"</span>, preprocess_text(text))
print(<span class="str">"Preprocessed (spaCy):"</span>, preprocess_with_spacy(text))

<span class="com"># Output:</span>
<span class="com"># Original: I'm running through the forest very happily!</span>
<span class="com"># Preprocessed (NLTK): ['run', 'forest', 'happily']</span>
<span class="com"># Preprocessed (spaCy): ['run', 'forest', 'happily']</span>
                </code>
            </div>

            <h3>Key Functions Explained</h3>
            <div class="comparison-grid">
                <div class="card">
                    <h4 style="color: var(--accent);">nltk.word_tokenize()</h4>
                    <p>Splits text into word tokens. Handles punctuation and contractions well.</p>
                </div>
                <div class="card">
                    <h4 style="color: var(--accent);">PorterStemmer.stem()</h4>
                    <p>Applies rule-based stemming. Fast but may produce non-words.</p>
                </div>
                <div class="card">
                    <h4 style="color: var(--accent);">WordNetLemmatizer.lemmatize()</h4>
                    <p>Dictionary-based lemmatization. Returns valid English words.</p>
                </div>
                <div class="card">
                    <h4 style="color: var(--accent);">stopwords.words('english')</h4>
                    <p>Pre-defined list of 179 common English stop words to filter out.</p>
                </div>
            </div>
        </section>

        <!-- Translation Connection -->
        <section>
            <h2>Connection: Building Ancient Language Translators</h2>
            <p>Text preprocessing becomes even more critical when working with ancient or low-resource languages. Here's how it connects to our translation system:</p>

            <div class="card">
                <h3>Special Challenges for Ancient Languages</h3>
                <ul style="list-style: none; padding: 0;">
                    <li style="margin-bottom: 1rem;">
                        <strong style="color: var(--accent);">Multiple Writing Systems:</strong> Ancient Egyptian, Cuneiform, Linear B each need custom tokenization rules. Standard word boundaries don't apply.
                    </li>
                    <li style="margin-bottom: 1rem;">
                        <strong style="color: var(--accent);">Morphological Complexity:</strong> Ancient Latin, Sanskrit, and Arabic have rich inflectional systems. Lemmatization must respect linguistic rules of the language.
                    </li>
                    <li style="margin-bottom: 1rem;">
                        <strong style="color: var(--accent);">Limited Corpora:</strong> Fewer training texts mean we can't rely on frequency-based stop word lists. Domain-specific terms matter more.
                    </li>
                    <li style="margin-bottom: 1rem;">
                        <strong style="color: var(--accent);">Spelling Variation:</strong> Ancient texts have inconsistent spelling. Preprocessing must normalize variants to the canonical form.
                    </li>
                    <li style="margin-bottom: 1rem;">
                        <strong style="color: var(--accent);">Punctuation Absence:</strong> Many ancient texts lack punctuation. Sentence tokenization requires heuristics based on semantic markers.
                    </li>
                </ul>
            </div>

            <div class="card">
                <h3>Our Pipeline for Ancient Texts</h3>
                <p style="margin-bottom: 1rem;">When translating ancient languages, we extend the standard pipeline:</p>
                <svg class="pipeline-svg" viewBox="0 0 1000 100" xmlns="http://www.w3.org/2000/svg">
                    <!-- Character Encoding -->
                    <rect x="10" y="10" width="110" height="80" fill="#1a1a2e" stroke="#ff6b6b" stroke-width="2" rx="4"/>
                    <text x="65" y="55" text-anchor="middle" fill="#e0e0e8" font-size="12" font-weight="bold">Character</text>
                    <text x="65" y="70" text-anchor="middle" fill="#e0e0e8" font-size="12" font-weight="bold">Encoding</text>

                    <line x1="130" y1="50" x2="160" y2="50" stroke="#8888a0" stroke-width="2" marker-end="url(#arrowhead)"/>

                    <!-- Normalize -->
                    <rect x="170" y="10" width="110" height="80" fill="#1a1a2e" stroke="#00d2ff" stroke-width="2" rx="4"/>
                    <text x="225" y="55" text-anchor="middle" fill="#e0e0e8" font-size="12" font-weight="bold">Normalize</text>
                    <text x="225" y="70" text-anchor="middle" fill="#e0e0e8" font-size="12" font-weight="bold">Spelling</text>

                    <line x1="290" y1="50" x2="320" y2="50" stroke="#8888a0" stroke-width="2" marker-end="url(#arrowhead)"/>

                    <!-- Custom Tokenize -->
                    <rect x="330" y="10" width="110" height="80" fill="#1a1a2e" stroke="#ff6b6b" stroke-width="2" rx="4"/>
                    <text x="385" y="55" text-anchor="middle" fill="#e0e0e8" font-size="12" font-weight="bold">Custom</text>
                    <text x="385" y="70" text-anchor="middle" fill="#e0e0e8" font-size="12" font-weight="bold">Tokenize</text>

                    <line x1="450" y1="50" x2="480" y2="50" stroke="#8888a0" stroke-width="2" marker-end="url(#arrowhead)"/>

                    <!-- Language-Aware -->
                    <rect x="490" y="10" width="110" height="80" fill="#1a1a2e" stroke="#6c63ff" stroke-width="2" rx="4"/>
                    <text x="545" y="55" text-anchor="middle" fill="#e0e0e8" font-size="12" font-weight="bold">Language-</text>
                    <text x="545" y="70" text-anchor="middle" fill="#e0e0e8" font-size="12" font-weight="bold">Aware Rules</text>

                    <line x1="610" y1="50" x2="640" y2="50" stroke="#8888a0" stroke-width="2" marker-end="url(#arrowhead)"/>

                    <!-- Remove Diacritics -->
                    <rect x="650" y="10" width="110" height="80" fill="#1a1a2e" stroke="#6c63ff" stroke-width="2" rx="4"/>
                    <text x="705" y="55" text-anchor="middle" fill="#e0e0e8" font-size="12" font-weight="bold">Diacritics</text>
                    <text x="705" y="70" text-anchor="middle" fill="#e0e0e8" font-size="12" font-weight="bold">Management</text>

                    <line x1="770" y1="50" x2="800" y2="50" stroke="#8888a0" stroke-width="2" marker-end="url(#arrowhead)"/>

                    <!-- Context -->
                    <rect x="810" y="10" width="110" height="80" fill="#1a1a2e" stroke="#6c63ff" stroke-width="2" rx="4"/>
                    <text x="865" y="55" text-anchor="middle" fill="#e0e0e8" font-size="12" font-weight="bold">Preserve</text>
                    <text x="865" y="70" text-anchor="middle" fill="#e0e0e8" font-size="12" font-weight="bold">Context</text>

                    <defs>
                        <marker id="arrowhead" markerWidth="10" markerHeight="10" refX="5" refY="5" orient="auto">
                            <polygon points="0 0, 10 5, 0 10" fill="#8888a0"/>
                        </marker>
                    </defs>
                </svg>
            </div>

            <p style="margin-top: 1.5rem; padding: 1rem; background: rgba(0, 210, 255, 0.1); border-radius: 8px;">
                <strong>Next step:</strong> Once texts are properly preprocessed, we convert them into numerical representations (embeddings) that neural networks can understand. That's what Module 02: Text Representation is all about.
            </p>
        </section>

        <!-- Footer with navigation -->
        <footer>
            <a href="index.html">← Back to Course</a>
            <a href="02-representation.html">Next: Text Representation →</a>
        </footer>
    </div>

    <script>
        // Intersection Observer for scroll animations
        const observer = new IntersectionObserver((entries) => {
            entries.forEach(entry => {
                if (entry.isIntersecting) {
                    entry.target.classList.add('scroll-in');
                    observer.unobserve(entry.target);
                }
            });
        }, { threshold: 0.1 });

        document.querySelectorAll('section').forEach(section => {
            observer.observe(section);
        });

        // Common stop words
        const stopWordsSet = new Set([
            'the', 'be', 'to', 'of', 'and', 'a', 'in', 'that', 'have', 'i',
            'it', 'for', 'not', 'on', 'with', 'he', 'as', 'you', 'do', 'at',
            'this', 'but', 'his', 'by', 'from', 'they', 'we', 'say', 'her', 'she',
            'or', 'an', 'will', 'my', 'one', 'all', 'would', 'there', 'their', 'what',
            'so', 'up', 'out', 'if', 'about', 'who', 'get', 'which', 'go', 'me',
            'when', 'make', 'can', 'like', 'time', 'no', 'just', 'him', 'know', 'take',
            'people', 'into', 'year', 'your', 'good', 'some', 'could', 'them', 'see', 'other',
            'than', 'then', 'now', 'look', 'only', 'come', 'its', 'over', 'think', 'also',
            'back', 'after', 'use', 'two', 'how', 'our', 'work', 'first', 'well', 'way',
            'even', 'new', 'want', 'because', 'any', 'these', 'give', 'day', 'most', 'us'
        ]);

        // Simple stemming rules (Porter-like)
        function simpleStem(word) {
            word = word.toLowerCase();

            if (word.endsWith('ies') && word.length > 3) return word.slice(0, -3) + 'i';
            if (word.endsWith('es') && word.length > 3) return word.slice(0, -2);
            if (word.endsWith('ed') && word.length > 3) return word.slice(0, -2);
            if (word.endsWith('ing') && word.length > 4) return word.slice(0, -3);
            if (word.endsWith('ly') && word.length > 4) return word.slice(0, -2);
            if (word.endsWith('tion') && word.length > 4) return word.slice(0, -4);
            if (word.endsWith('s') && word.length > 2) return word.slice(0, -1);

            return word;
        }

        // Simple lemmatization rules
        function simpleLemma(word) {
            word = word.toLowerCase();

            const lemmaMap = {
                'running': 'run', 'runs': 'run', 'ran': 'run',
                'studies': 'study', 'studied': 'study',
                'better': 'good',
                'played': 'play', 'plays': 'play',
                'agreed': 'agree', 'agrees': 'agree',
                'eating': 'eat', 'eats': 'eat', 'ate': 'eat',
                'happiness': 'happiness', 'happy': 'happy',
                'organizational': 'organizational', 'organize': 'organize',
                'said': 'say', 'says': 'say',
                'going': 'go', 'goes': 'go', 'went': 'go',
                'caring': 'care', 'cares': 'care', 'cared': 'care',
                'thinking': 'think', 'thinks': 'think', 'thought': 'think',
                'breaking': 'break', 'breaks': 'break', 'broke': 'break',
                'buying': 'buy', 'buys': 'buy', 'bought': 'buy',
                'getting': 'get', 'gets': 'get', 'got': 'get',
                'making': 'make', 'makes': 'make', 'made': 'make',
                'taking': 'take', 'takes': 'take', 'took': 'take',
            };

            return lemmaMap[word] || word;
        }

        // Tokenization functions
        function tokenizeWords() {
            const text = document.getElementById('tokenInput').value;
            const tokens = text.match(/\b[\w']+\b|[.,!?;]/g) || [];
            displayTokens(tokens, 'word');
            document.getElementById('explanationText').textContent =
                'Word tokenization splits text on whitespace and punctuation boundaries. Punctuation marks like periods and commas become separate tokens. This is the most common tokenization method.';
            document.getElementById('tokenExplanation').style.display = 'block';
        }

        function tokenizeSentences() {
            const text = document.getElementById('tokenInput').value;
            const sentences = text.split(/[.!?]+/).filter(s => s.trim().length > 0);
            displayTokens(sentences, 'sentence');
            document.getElementById('explanationText').textContent =
                'Sentence tokenization identifies sentence boundaries using period, question mark, and exclamation mark delimiters. Useful for document-level analysis and processing multi-sentence inputs.';
            document.getElementById('tokenExplanation').style.display = 'block';
        }

        function tokenizeSubword() {
            const text = document.getElementById('tokenInput').value.toLowerCase();
            const words = text.match(/\b[\w']+\b/g) || [];
            const subwords = [];

            words.forEach(word => {
                if (word.length > 4) {
                    subwords.push(word.slice(0, 3));
                    subwords.push('##' + word.slice(3));
                } else {
                    subwords.push(word);
                }
            });

            displayTokens(subwords, 'subword');
            document.getElementById('explanationText').textContent =
                'Byte-Pair Encoding (BPE) breaks words into subword units. Long words are split with ## prefix marking continuation. Modern transformers like BERT use this to handle rare words and morphology.';
            document.getElementById('tokenExplanation').style.display = 'block';
        }

        function displayTokens(tokens, type) {
            const output = document.getElementById('tokenOutput');
            output.innerHTML = '<h4 style="color: var(--accent); margin-bottom: 1rem;">Tokens:</h4><div class="tokens">';

            tokens.forEach(token => {
                const tokenDiv = document.createElement('span');
                tokenDiv.className = 'token';
                if (type === 'subword') tokenDiv.className += ' subword';
                tokenDiv.textContent = token.trim();
                output.querySelector('.tokens').appendChild(tokenDiv);
            });

            output.innerHTML += '</div>';
            output.innerHTML += `<p style="color: var(--muted); font-size: 0.9rem; margin-top: 1rem;">Total tokens: ${tokens.length}</p>`;
        }

        // Word input listener for stemming/lemmatization
        document.getElementById('wordInput').addEventListener('input', function() {
            const word = this.value.toLowerCase();
            document.getElementById('stemResult').textContent = simpleStem(word);
            document.getElementById('lemmaResult').textContent = simpleLemma(word);
        });

        // Initial display for word comparison
        document.getElementById('wordInput').dispatchEvent(new Event('input'));

        // Stop word toggle
        let showingStopwords = true;

        function toggleStopwords() {
            showingStopwords = !showingStopwords;
            const btn = document.getElementById('toggleStopwords');
            btn.textContent = showingStopwords ? 'Remove Stop Words' : 'Show Stop Words';
            updateStopwordDisplay();
        }

        function updateStopwordDisplay() {
            const paragraph = `Natural language processing is fascinating because it enables computers to understand and process human language in meaningful ways that were previously impossible.`;
            const words = paragraph.match(/\b[\w']+\b/g) || [];
            const container = document.getElementById('stopwordText');

            container.innerHTML = '';
            let cleanWords = [];

            words.forEach(word => {
                const isStop = stopWordsSet.has(word.toLowerCase());
                const span = document.createElement('span');

                if (!showingStopwords && isStop) {
                    // Skip rendering
                } else if (isStop) {
                    span.className = 'highlighted';
                    span.textContent = word + ' ';
                } else {
                    span.textContent = word + ' ';
                    cleanWords.push(word);
                }

                container.appendChild(span);
            });

            document.getElementById('originalCount').textContent = words.length;
            document.getElementById('cleanCount').textContent = cleanWords.length;
        }

        // Initialize stop word display
        updateStopwordDisplay();

        // Pipeline visualization
        function runPipeline() {
            const text = document.getElementById('pipelineInput').value.trim();
            if (!text) return;

            const stages = [
                {
                    name: '1. Original Text',
                    result: text
                },
                {
                    name: '2. Lowercase',
                    result: text.toLowerCase()
                },
                {
                    name: '3. Remove Special Characters',
                    result: text.toLowerCase().replace(/[^a-z0-9\s]/g, '')
                },
                {
                    name: '4. Tokenize',
                    result: text.toLowerCase()
                        .replace(/[^a-z0-9\s]/g, '')
                        .split(/\s+/)
                        .filter(t => t.length > 0)
                        .join(' ')
                },
                {
                    name: '5. Remove Stop Words',
                    result: text.toLowerCase()
                        .replace(/[^a-z0-9\s]/g, '')
                        .split(/\s+/)
                        .filter(t => t.length > 0 && !stopWordsSet.has(t))
                        .join(' ')
                }
            ];

            const last = stages[stages.length - 1];
            const lemmatized = last.result.split(/\s+/)
                .map(w => simpleLemma(w))
                .join(' ');

            stages.push({
                name: '6. Lemmatize',
                result: lemmatized
            });

            const container = document.getElementById('pipelineContainer');
            container.innerHTML = '';

            stages.forEach((stage, idx) => {
                const stageDiv = document.createElement('div');
                stageDiv.className = 'pipeline-stage';
                stageDiv.style.animationDelay = (idx * 0.1) + 's';

                const h4 = document.createElement('h4');
                h4.textContent = stage.name;
                stageDiv.appendChild(h4);

                const inputDiv = document.createElement('div');
                inputDiv.className = 'input';
                inputDiv.textContent = stage.result;
                stageDiv.appendChild(inputDiv);

                container.appendChild(stageDiv);
            });
        }

        // Smooth scroll for anchor links
        document.querySelectorAll('a[href^="#"]').forEach(anchor => {
            anchor.addEventListener('click', function(e) {
                e.preventDefault();
                const target = document.querySelector(this.getAttribute('href'));
                if (target) {
                    target.scrollIntoView({ behavior: 'smooth' });
                }
            });
        });
    </script>
</body>
</html>
