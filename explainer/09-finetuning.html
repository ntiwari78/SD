<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Module 09: Fine-Tuning - NLP Course</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            background: #0a0a0f;
            color: #e0e0e8;
            font-family: Inter, system-ui, -apple-system, sans-serif;
            line-height: 1.6;
            font-size: 16px;
        }

        /* Navigation Bar */
        nav {
            position: sticky;
            top: 0;
            background: rgba(10, 10, 15, 0.95);
            backdrop-filter: blur(10px);
            border-bottom: 1px solid #2a2a3e;
            padding: 1rem 2rem;
            z-index: 1000;
            display: flex;
            align-items: center;
        }

        nav a {
            color: #6c63ff;
            text-decoration: none;
            font-weight: 500;
            display: flex;
            align-items: center;
            gap: 0.5rem;
            transition: color 0.3s;
        }

        nav a:hover {
            color: #00d2ff;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 2rem;
        }

        /* Animations */
        @keyframes fadeInUp {
            from {
                opacity: 0;
                transform: translateY(30px);
            }
            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        @keyframes fadeIn {
            from {
                opacity: 0;
            }
            to {
                opacity: 1;
            }
        }

        @keyframes pulse {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.7; }
        }

        .scroll-fade {
            opacity: 0;
            transform: translateY(30px);
            transition: all 0.8s ease-out;
        }

        .scroll-fade.visible {
            opacity: 1;
            transform: translateY(0);
        }

        /* Hero Section */
        .hero {
            text-align: center;
            padding: 4rem 2rem;
            margin-bottom: 3rem;
        }

        .hero h1 {
            font-size: 3.5rem;
            font-weight: 700;
            margin-bottom: 1rem;
            background: linear-gradient(135deg, #6c63ff, #00d2ff);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
        }

        .hero .subtitle {
            font-size: 1.5rem;
            color: #8888a0;
            margin-bottom: 1rem;
        }

        .hero .duration {
            color: #6c63ff;
            font-weight: 600;
        }

        /* Section Headers */
        .section {
            margin-bottom: 4rem;
            scroll-margin-top: 80px;
        }

        .section h2 {
            font-size: 2rem;
            margin-bottom: 1.5rem;
            color: #00d2ff;
            border-left: 4px solid #6c63ff;
            padding-left: 1rem;
        }

        .section h3 {
            font-size: 1.3rem;
            color: #6c63ff;
            margin-top: 1.5rem;
            margin-bottom: 1rem;
        }

        .section p {
            margin-bottom: 1rem;
            color: #c8c8d0;
            line-height: 1.8;
        }

        /* Cards */
        .card {
            background: #1a1a2e;
            border: 1px solid #2a2a3e;
            border-radius: 12px;
            padding: 1.5rem;
            margin-bottom: 1.5rem;
            transition: all 0.3s ease;
        }

        .card:hover {
            border-color: #6c63ff;
            box-shadow: 0 0 20px rgba(108, 99, 255, 0.2);
        }

        .card-title {
            font-size: 1.1rem;
            font-weight: 600;
            color: #00d2ff;
            margin-bottom: 0.8rem;
        }

        .card-text {
            color: #a8a8b8;
            font-size: 0.95rem;
        }

        /* Interactive Controls */
        .interactive-container {
            background: #12121a;
            border: 1px solid #2a2a3e;
            border-radius: 12px;
            padding: 2rem;
            margin: 2rem 0;
        }

        .toggle-group {
            display: flex;
            gap: 1rem;
            margin-bottom: 2rem;
        }

        .toggle-btn {
            flex: 1;
            padding: 0.75rem 1.5rem;
            border: 2px solid #2a2a3e;
            background: #1a1a2e;
            color: #e0e0e8;
            border-radius: 8px;
            cursor: pointer;
            font-weight: 600;
            transition: all 0.3s;
            font-size: 1rem;
        }

        .toggle-btn.active {
            background: #6c63ff;
            border-color: #6c63ff;
            color: white;
        }

        .toggle-btn:hover {
            border-color: #6c63ff;
        }

        /* Slider */
        input[type="range"] {
            width: 100%;
            height: 6px;
            border-radius: 3px;
            background: #2a2a3e;
            outline: none;
            -webkit-appearance: none;
            margin: 1rem 0;
        }

        input[type="range"]::-webkit-slider-thumb {
            -webkit-appearance: none;
            appearance: none;
            width: 20px;
            height: 20px;
            border-radius: 50%;
            background: #6c63ff;
            cursor: pointer;
            transition: all 0.3s;
        }

        input[type="range"]::-webkit-slider-thumb:hover {
            background: #00d2ff;
            box-shadow: 0 0 10px rgba(0, 210, 255, 0.5);
        }

        input[type="range"]::-moz-range-thumb {
            width: 20px;
            height: 20px;
            border-radius: 50%;
            background: #6c63ff;
            cursor: pointer;
            border: none;
            transition: all 0.3s;
        }

        .slider-label {
            display: flex;
            justify-content: space-between;
            margin-bottom: 1rem;
            font-weight: 600;
        }

        .slider-value {
            color: #6c63ff;
        }

        /* Chart Container */
        .chart-container {
            background: #12121a;
            border: 1px solid #2a2a3e;
            border-radius: 12px;
            padding: 2rem;
            margin: 1.5rem 0;
            height: 300px;
            position: relative;
        }

        /* Table */
        .comparison-table {
            width: 100%;
            border-collapse: collapse;
            margin: 2rem 0;
        }

        .comparison-table th {
            background: #1a1a2e;
            border: 1px solid #2a2a3e;
            padding: 1rem;
            text-align: left;
            font-weight: 600;
            color: #00d2ff;
        }

        .comparison-table td {
            border: 1px solid #2a2a3e;
            padding: 1rem;
            color: #c8c8d0;
        }

        .comparison-table tr:hover {
            background: rgba(108, 99, 255, 0.1);
        }

        /* Code Block */
        .code-block {
            background: #12121a;
            border: 1px solid #2a2a3e;
            border-radius: 8px;
            padding: 1.5rem;
            overflow-x: auto;
            margin: 1.5rem 0;
            font-family: 'Monaco', 'Courier New', monospace;
            font-size: 0.9rem;
            line-height: 1.6;
        }

        .code-block code {
            color: #00d2ff;
        }

        .code-comment { color: #6b8e23; }
        .code-keyword { color: #ff6b6b; }
        .code-string { color: #00d2ff; }
        .code-function { color: #6c63ff; }

        /* SVG Styling */
        svg {
            max-width: 100%;
            height: auto;
            margin: 1rem 0;
        }

        .svg-container {
            display: flex;
            justify-content: center;
            margin: 2rem 0;
        }

        /* Tabs */
        .tabs {
            display: flex;
            gap: 1rem;
            margin: 1.5rem 0;
            border-bottom: 1px solid #2a2a3e;
        }

        .tab-btn {
            padding: 0.75rem 1.5rem;
            background: none;
            border: none;
            color: #8888a0;
            cursor: pointer;
            font-weight: 600;
            border-bottom: 2px solid transparent;
            transition: all 0.3s;
            font-size: 0.95rem;
        }

        .tab-btn.active {
            color: #00d2ff;
            border-bottom-color: #00d2ff;
        }

        .tab-content {
            display: none;
        }

        .tab-content.active {
            display: block;
            animation: fadeIn 0.3s;
        }

        /* Grid for Examples */
        .example-grid {
            display: grid;
            gap: 1.5rem;
            margin: 2rem 0;
        }

        .example-card {
            background: #1a1a2e;
            border: 1px solid #2a2a3e;
            border-radius: 12px;
            padding: 1.5rem;
            transition: all 0.3s;
        }

        .example-card:hover {
            border-color: #00d2ff;
            transform: translateY(-2px);
        }

        .example-label {
            color: #6c63ff;
            font-size: 0.85rem;
            font-weight: 700;
            text-transform: uppercase;
            margin-bottom: 0.5rem;
        }

        .example-text {
            color: #c8c8d0;
            font-family: 'Monaco', monospace;
            font-size: 0.9rem;
            line-height: 1.6;
            white-space: pre-wrap;
        }

        /* Footer Navigation */
        .nav-footer {
            display: flex;
            justify-content: space-between;
            margin: 4rem 0 2rem;
            padding-top: 2rem;
            border-top: 1px solid #2a2a3e;
        }

        .nav-footer a {
            display: flex;
            align-items: center;
            gap: 0.5rem;
            color: #6c63ff;
            text-decoration: none;
            font-weight: 600;
            transition: color 0.3s;
        }

        .nav-footer a:hover {
            color: #00d2ff;
        }

        .nav-footer .next {
            margin-left: auto;
        }

        /* Responsive */
        @media (max-width: 768px) {
            .hero h1 {
                font-size: 2.5rem;
            }

            .section h2 {
                font-size: 1.5rem;
            }

            .container {
                padding: 1rem;
            }

            .toggle-group {
                flex-direction: column;
            }

            .comparison-table {
                font-size: 0.85rem;
            }

            .comparison-table th,
            .comparison-table td {
                padding: 0.75rem 0.5rem;
            }
        }
    </style>
</head>
<body>
    <nav>
        <a href="index.html">‚Üê Back to Course</a>
    </nav>

    <div class="container">
        <!-- Hero Section -->
        <section class="hero scroll-fade">
            <h1>Module 09: Fine-Tuning</h1>
            <p class="subtitle">Standing on the Shoulders of Giants</p>
            <p class="duration">‚è±Ô∏è ~25 minutes</p>
        </section>

        <!-- Transfer Learning Visual -->
        <section class="section scroll-fade">
            <h2>Transfer Learning: From General to Specific</h2>
            <p>
                Rather than training a model from scratch on your small dataset, you can leverage models trained on massive corpora. Fine-tuning adjusts a pre-trained model's weights to excel at your specific task.
            </p>

            <div class="svg-container">
                <svg width="100%" height="300" viewBox="0 0 800 300" style="max-width: 600px;">
                    <!-- Pre-training corpus -->
                    <g>
                        <rect x="20" y="40" width="120" height="80" fill="#2a2a3e" stroke="#6c63ff" stroke-width="2" rx="8"/>
                        <text x="80" y="75" text-anchor="middle" fill="#e0e0e8" font-weight="bold">Pre-training</text>
                        <text x="80" y="95" text-anchor="middle" fill="#8888a0" font-size="12">Books, Web,</text>
                        <text x="80" y="110" text-anchor="middle" fill="#8888a0" font-size="12">Wikipedia</text>
                    </g>

                    <!-- Arrow 1 -->
                    <path d="M 140 80 L 180 80" stroke="#6c63ff" stroke-width="3" fill="none" marker-end="url(#arrowhead)"/>

                    <!-- Pre-trained model -->
                    <g>
                        <rect x="180" y="20" width="120" height="120" fill="#1a1a2e" stroke="#00d2ff" stroke-width="2" rx="8"/>
                        <text x="240" y="75" text-anchor="middle" fill="#e0e0e8" font-weight="bold">Pre-trained</text>
                        <text x="240" y="95" text-anchor="middle" fill="#e0e0e8" font-weight="bold">Model</text>
                        <!-- Weight grid visualization -->
                        <g id="weight-grid-1">
                            <circle cx="200" cy="40" r="3" fill="#ff6b6b" opacity="0.8"/>
                            <circle cx="210" cy="45" r="3" fill="#ff6b6b" opacity="0.8"/>
                            <circle cx="220" cy="40" r="3" fill="#ff6b6b" opacity="0.8"/>
                            <circle cx="200" cy="60" r="3" fill="#ff6b6b" opacity="0.8"/>
                            <circle cx="210" cy="65" r="3" fill="#ff6b6b" opacity="0.8"/>
                            <circle cx="220" cy="60" r="3" fill="#ff6b6b" opacity="0.8"/>
                        </g>
                    </g>

                    <!-- Arrow 2 -->
                    <path d="M 300 80 L 340 80" stroke="#6c63ff" stroke-width="3" fill="none" marker-end="url(#arrowhead)"/>

                    <!-- Task-specific data -->
                    <g>
                        <rect x="340" y="40" width="120" height="80" fill="#2a2a3e" stroke="#6c63ff" stroke-width="2" rx="8"/>
                        <text x="400" y="70" text-anchor="middle" fill="#e0e0e8" font-weight="bold">Task-specific</text>
                        <text x="400" y="90" text-anchor="middle" fill="#e0e0e8" font-weight="bold">Dataset</text>
                        <text x="400" y="110" text-anchor="middle" fill="#8888a0" font-size="12">(Small!)</text>
                    </g>

                    <!-- Arrow 3 -->
                    <path d="M 460 80 L 500 80" stroke="#6c63ff" stroke-width="3" fill="none" marker-end="url(#arrowhead)"/>

                    <!-- Fine-tuned model -->
                    <g>
                        <rect x="500" y="20" width="120" height="120" fill="#1a1a2e" stroke="#00d2ff" stroke-width="2" rx="8"/>
                        <text x="560" y="60" text-anchor="middle" fill="#e0e0e8" font-weight="bold">Fine-tuned</text>
                        <text x="560" y="80" text-anchor="middle" fill="#e0e0e8" font-weight="bold">Model</text>
                        <!-- Weight grid showing updated weights -->
                        <g id="weight-grid-2">
                            <circle cx="520" cy="40" r="3" fill="#ff6b6b" opacity="0.8"/>
                            <circle cx="530" cy="45" r="3" fill="#00d2ff" opacity="0.8"/>
                            <circle cx="540" cy="40" r="3" fill="#ff6b6b" opacity="0.8"/>
                            <circle cx="520" cy="60" r="3" fill="#ff6b6b" opacity="0.8"/>
                            <circle cx="530" cy="65" r="3" fill="#00d2ff" opacity="0.8"/>
                            <circle cx="540" cy="60" r="3" fill="#ff6b6b" opacity="0.8"/>
                        </g>
                    </g>

                    <!-- Arrow marker definition -->
                    <defs>
                        <marker id="arrowhead" markerWidth="10" markerHeight="10" refX="9" refY="3" orient="auto">
                            <polygon points="0 0, 10 3, 0 6" fill="#6c63ff"/>
                        </marker>
                    </defs>

                    <!-- Bottom insight -->
                    <text x="400" y="280" text-anchor="middle" fill="#00d2ff" font-weight="bold">You don't need millions of examples anymore!</text>
                </svg>
            </div>

            <div class="card">
                <div class="card-title">Key Insight</div>
                <div class="card-text">
                    Pre-training on massive corpora learns general language patterns. Fine-tuning on your small, specific dataset adapts these patterns to your task. This is why modern NLP is possible with limited labeled data.
                </div>
            </div>
        </section>

        <!-- Full Fine-Tuning vs Feature Extraction -->
        <section class="section scroll-fade">
            <h2>Two Approaches: Full Fine-Tuning vs Feature Extraction</h2>
            <p>
                Depending on your dataset size and compute budget, you have two strategies. Toggle below to see how they differ.
            </p>

            <div class="interactive-container">
                <div class="toggle-group">
                    <button class="toggle-btn active" onclick="switchStrategy('feature')">Feature Extraction</button>
                    <button class="toggle-btn" onclick="switchStrategy('fullft')">Full Fine-Tuning</button>
                </div>

                <div id="strategy-content">
                    <!-- Feature Extraction Content -->
                    <div id="feature-strategy" style="display: block;">
                        <h3>Feature Extraction (Frozen Backbone)</h3>
                        <p style="margin-bottom: 1.5rem;">
                            Freeze all pre-trained layers and only train a new classification head. Perfect for small datasets.
                        </p>

                        <svg width="100%" height="250" viewBox="0 0 400 250" style="max-width: 100%;">
                            <!-- Frozen layers -->
                            <g>
                                <text x="200" y="20" text-anchor="middle" fill="#e0e0e8" font-size="14" font-weight="bold">Feature Extraction Architecture</text>
                            </g>

                            <!-- Layer boxes (frozen) -->
                            <g opacity="0.5">
                                <rect x="100" y="50" width="200" height="25" fill="#2a2a3e" stroke="#6b8e23" stroke-width="2" rx="4"/>
                                <text x="200" y="67" text-anchor="middle" fill="#6b8e23" font-size="12" font-weight="bold">üîí Embedding Layer (Frozen)</text>
                            </g>

                            <g opacity="0.5">
                                <rect x="100" y="85" width="200" height="25" fill="#2a2a3e" stroke="#6b8e23" stroke-width="2" rx="4"/>
                                <text x="200" y="102" text-anchor="middle" fill="#6b8e23" font-size="12" font-weight="bold">üîí Transformer Block 1 (Frozen)</text>
                            </g>

                            <g opacity="0.5">
                                <rect x="100" y="120" width="200" height="25" fill="#2a2a3e" stroke="#6b8e23" stroke-width="2" rx="4"/>
                                <text x="200" y="137" text-anchor="middle" fill="#6b8e23" font-size="12" font-weight="bold">üîí Transformer Block 2 (Frozen)</text>
                            </g>

                            <!-- Trainable head -->
                            <g>
                                <rect x="100" y="155" width="200" height="25" fill="#1a1a2e" stroke="#00d2ff" stroke-width="2" rx="4"/>
                                <text x="200" y="172" text-anchor="middle" fill="#00d2ff" font-size="12" font-weight="bold">üîì Classification Head (Trained)</text>
                            </g>

                            <!-- Output -->
                            <rect x="100" y="195" width="200" height="25" fill="#6c63ff" stroke="#6c63ff" stroke-width="2" rx="4"/>
                            <text x="200" y="212" text-anchor="middle" fill="white" font-size="12" font-weight="bold">Task Output</text>
                        </svg>

                        <div class="card">
                            <div class="card-title">When to Use</div>
                            <div class="card-text">
                                ‚úì Small dataset (&lt;5K examples)<br/>
                                ‚úì Limited compute resources<br/>
                                ‚úì Fast training required<br/>
                                ‚úó May limit performance on complex tasks
                            </div>
                        </div>
                    </div>

                    <!-- Full Fine-Tuning Content -->
                    <div id="fullft-strategy" style="display: none;">
                        <h3>Full Fine-Tuning</h3>
                        <p style="margin-bottom: 1.5rem;">
                            Unfreeze all layers and train everything with a small learning rate. Better performance but needs more data and compute.
                        </p>

                        <svg width="100%" height="250" viewBox="0 0 400 250" style="max-width: 100%;">
                            <!-- Trainable layers -->
                            <g>
                                <text x="200" y="20" text-anchor="middle" fill="#e0e0e8" font-size="14" font-weight="bold">Full Fine-Tuning Architecture</text>
                            </g>

                            <!-- Layer boxes (trainable) -->
                            <g>
                                <rect x="100" y="50" width="200" height="25" fill="#1a1a2e" stroke="#00d2ff" stroke-width="2" rx="4"/>
                                <text x="200" y="67" text-anchor="middle" fill="#00d2ff" font-size="12" font-weight="bold">üîì Embedding Layer (Trained)</text>
                            </g>

                            <g>
                                <rect x="100" y="85" width="200" height="25" fill="#1a1a2e" stroke="#00d2ff" stroke-width="2" rx="4"/>
                                <text x="200" y="102" text-anchor="middle" fill="#00d2ff" font-size="12" font-weight="bold">üîì Transformer Block 1 (Trained)</text>
                            </g>

                            <g>
                                <rect x="100" y="120" width="200" height="25" fill="#1a1a2e" stroke="#00d2ff" stroke-width="2" rx="4"/>
                                <text x="200" y="137" text-anchor="middle" fill="#00d2ff" font-size="12" font-weight="bold">üîì Transformer Block 2 (Trained)</text>
                            </g>

                            <!-- Head -->
                            <g>
                                <rect x="100" y="155" width="200" height="25" fill="#1a1a2e" stroke="#00d2ff" stroke-width="2" rx="4"/>
                                <text x="200" y="172" text-anchor="middle" fill="#00d2ff" font-size="12" font-weight="bold">üîì Classification Head (Trained)</text>
                            </g>

                            <!-- Output -->
                            <rect x="100" y="195" width="200" height="25" fill="#6c63ff" stroke="#6c63ff" stroke-width="2" rx="4"/>
                            <text x="200" y="212" text-anchor="middle" fill="white" font-size="12" font-weight="bold">Task Output</text>
                        </svg>

                        <div class="card">
                            <div class="card-title">When to Use</div>
                            <div class="card-text">
                                ‚úì Medium-to-large dataset (&gt;5K examples)<br/>
                                ‚úì Sufficient compute resources<br/>
                                ‚úì Best performance on complex tasks<br/>
                                ‚úó Longer training, risk of overfitting
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </section>

        <!-- Learning Rate Strategy -->
        <section class="section scroll-fade">
            <h2>Learning Rate Strategy: The Fine-Tuning Sweet Spot</h2>
            <p>
                The learning rate controls how quickly weights change. Too high and the model diverges, too low and training is glacial. Use the slider to explore.
            </p>

            <div class="interactive-container">
                <div class="slider-label">
                    <span>Learning Rate:</span>
                    <span class="slider-value" id="lr-value">5e-5</span>
                </div>
                <input type="range" min="-5" max="-3" step="0.1" value="-5" onchange="updateLearningRate(this.value)" oninput="updateLearningRate(this.value)">
                <small style="color: #8888a0;">Range: 1e-5 to 1e-3</small>

                <div class="chart-container" style="margin-top: 2rem;">
                    <canvas id="loss-chart" style="width: 100%; height: 100%;"></canvas>
                </div>
            </div>

            <div class="example-grid">
                <div class="example-card">
                    <div class="example-label">Too High (e.g., 1e-3)</div>
                    <p style="margin: 1rem 0; color: #ff6b6b;">Loss diverges wildly. Model forgets pre-trained knowledge.</p>
                </div>
                <div class="example-card">
                    <div class="example-label">Too Low (e.g., 1e-6)</div>
                    <p style="margin: 1rem 0; color: #ffbb00;">Extremely slow convergence. May never fully adapt.</p>
                </div>
                <div class="example-card">
                    <div class="example-label">Just Right (e.g., 5e-5)</div>
                    <p style="margin: 1rem 0; color: #00d2ff;">Smooth convergence. Preserves pre-trained knowledge.</p>
                </div>
            </div>

            <h3>Discriminative Learning Rates</h3>
            <p>
                Advanced technique: use smaller learning rates for lower layers (general features) and larger rates for upper layers (task-specific).
            </p>

            <svg width="100%" height="200" viewBox="0 0 500 200" style="max-width: 100%;">
                <text x="250" y="20" text-anchor="middle" fill="#e0e0e8" font-size="14" font-weight="bold">Discriminative Learning Rates</text>

                <!-- Layer 1 (smallest LR) -->
                <rect x="50" y="50" width="60" height="80" fill="#1a1a2e" stroke="#6b8e23" stroke-width="2" rx="4"/>
                <text x="80" y="85" text-anchor="middle" fill="#6b8e23" font-size="12">Layer 1</text>
                <text x="80" y="105" text-anchor="middle" fill="#6b8e23" font-size="10" font-weight="bold">LR: 1e-6</text>
                <text x="80" y="120" text-anchor="middle" fill="#8888a0" font-size="9">(General)</text>

                <!-- Layer 2 -->
                <rect x="150" y="50" width="60" height="80" fill="#1a1a2e" stroke="#ffbb00" stroke-width="2" rx="4"/>
                <text x="180" y="85" text-anchor="middle" fill="#ffbb00" font-size="12">Layer 2</text>
                <text x="180" y="105" text-anchor="middle" fill="#ffbb00" font-size="10" font-weight="bold">LR: 5e-6</text>
                <text x="180" y="120" text-anchor="middle" fill="#8888a0" font-size="9">(Mid-level)</text>

                <!-- Layer 3 (largest LR) -->
                <rect x="250" y="50" width="60" height="80" fill="#1a1a2e" stroke="#00d2ff" stroke-width="2" rx="4"/>
                <text x="280" y="85" text-anchor="middle" fill="#00d2ff" font-size="12">Layer 3</text>
                <text x="280" y="105" text-anchor="middle" fill="#00d2ff" font-size="10" font-weight="bold">LR: 1e-4</text>
                <text x="280" y="120" text-anchor="middle" fill="#8888a0" font-size="9">(Task-specific)</text>

                <!-- Arrow showing LR increase -->
                <path d="M 80 160 L 280 160" stroke="#6c63ff" stroke-width="2" fill="none" marker-end="url(#arrowhead2)"/>
                <text x="180" y="185" text-anchor="middle" fill="#6c63ff" font-weight="bold">Learning Rate Increases ‚Üí</text>

                <defs>
                    <marker id="arrowhead2" markerWidth="10" markerHeight="10" refX="9" refY="3" orient="auto">
                        <polygon points="0 0, 10 3, 0 6" fill="#6c63ff"/>
                    </marker>
                </defs>
            </svg>

            <h3>Warmup Schedule</h3>
            <p>
                Gradually increase the learning rate from near-zero to your target value. This prevents harmful weight updates early in training.
            </p>
        </section>

        <!-- LoRA: Low-Rank Adaptation -->
        <section class="section scroll-fade">
            <h2>LoRA: Low-Rank Adaptation (The Modern Technique)</h2>
            <p>
                Instead of fine-tuning all billions of parameters, LoRA injects small, trainable "adapter" matrices. This reduces memory by 1000x while maintaining performance.
            </p>

            <h3>The Core Idea: Weight Decomposition</h3>
            <p>
                Rather than updating weight matrix W, you train low-rank matrices A and B such that: <strong>W_updated = W + B¬∑A</strong>
            </p>

            <div class="svg-container">
                <svg width="100%" height="350" viewBox="0 0 800 350" style="max-width: 700px;">
                    <text x="400" y="25" text-anchor="middle" fill="#e0e0e8" font-size="15" font-weight="bold">Weight Matrix Decomposition</text>

                    <!-- Full Weight Matrix -->
                    <g>
                        <text x="150" y="60" text-anchor="middle" fill="#00d2ff" font-size="13" font-weight="bold">Original Weight Matrix W</text>
                        <rect x="50" y="80" width="200" height="200" fill="#12121a" stroke="#2a2a3e" stroke-width="2" rx="4"/>

                        <!-- Grid cells to show dimensions -->
                        <g opacity="0.6">
                            <line x1="70" y1="80" x2="70" y2="280" stroke="#2a2a3e" stroke-width="1"/>
                            <line x1="90" y1="80" x2="90" y2="280" stroke="#2a2a3e" stroke-width="1"/>
                            <line x1="110" y1="80" x2="110" y2="280" stroke="#2a2a3e" stroke-width="1"/>
                            <line x1="130" y1="80" x2="130" y2="280" stroke="#2a2a3e" stroke-width="1"/>
                            <line x1="150" y1="80" x2="150" y2="280" stroke="#2a2a3e" stroke-width="1"/>
                            <line x1="170" y1="80" x2="170" y2="280" stroke="#2a2a3e" stroke-width="1"/>
                            <line x1="190" y1="80" x2="190" y2="280" stroke="#2a2a3e" stroke-width="1"/>
                            <line x1="210" y1="80" x2="210" y2="280" stroke="#2a2a3e" stroke-width="1"/>

                            <line x1="50" y1="100" x2="250" y2="100" stroke="#2a2a3e" stroke-width="1"/>
                            <line x1="50" y1="120" x2="250" y2="120" stroke="#2a2a3e" stroke-width="1"/>
                            <line x1="50" y1="140" x2="250" y2="140" stroke="#2a2a3e" stroke-width="1"/>
                            <line x1="50" y1="160" x2="250" y2="160" stroke="#2a2a3e" stroke-width="1"/>
                            <line x1="50" y1="180" x2="250" y2="180" stroke="#2a2a3e" stroke-width="1"/>
                            <line x1="50" y1="200" x2="250" y2="200" stroke="#2a2a3e" stroke-width="1"/>
                            <line x1="50" y1="220" x2="250" y2="220" stroke="#2a2a3e" stroke-width="1"/>
                            <line x1="50" y1="240" x2="250" y2="240" stroke="#2a2a3e" stroke-width="1"/>
                            <line x1="50" y1="260" x2="250" y2="260" stroke="#2a2a3e" stroke-width="1"/>
                        </g>

                        <!-- Colored cells to show diversity -->
                        <circle cx="80" cy="110" r="4" fill="#ff6b6b" opacity="0.8"/>
                        <circle cx="120" cy="150" r="4" fill="#00d2ff" opacity="0.8"/>
                        <circle cx="160" cy="190" r="4" fill="#6c63ff" opacity="0.8"/>
                        <circle cx="200" cy="230" r="4" fill="#00d2ff" opacity="0.8"/>

                        <text x="150" y="310" text-anchor="middle" fill="#8888a0" font-size="12">768 √ó 768 = 589K params</text>
                    </g>

                    <!-- Equals sign -->
                    <text x="320" y="185" text-anchor="middle" fill="#6c63ff" font-size="20" font-weight="bold">=</text>

                    <!-- Original W (small) -->
                    <g>
                        <text x="430" y="60" text-anchor="middle" fill="#ffbb00" font-size="13" font-weight="bold">Original W (frozen)</text>
                        <rect x="380" y="80" width="100" height="100" fill="#12121a" stroke="#6b8e23" stroke-width="2" rx="4" opacity="0.7"/>
                        <text x="430" y="140" text-anchor="middle" fill="#8888a0" font-size="11" font-weight="bold">768√ó768</text>
                    </g>

                    <!-- Plus sign -->
                    <text x="520" y="135" text-anchor="middle" fill="#6c63ff" font-size="20" font-weight="bold">+</text>

                    <!-- B matrix -->
                    <g>
                        <text x="620" y="60" text-anchor="middle" fill="#6c63ff" font-size="13" font-weight="bold">B¬∑A (trained)</text>
                        <rect x="570" y="80" width="100" height="100" fill="#1a1a2e" stroke="#6c63ff" stroke-width="2" rx="4"/>

                        <!-- Show internal decomposition -->
                        <text x="620" y="125" text-anchor="middle" fill="#e0e0e8" font-size="10" font-weight="bold">768√ó16</text>
                        <text x="620" y="140" text-anchor="middle" fill="#e0e0e8" font-size="10">√ó</text>
                        <text x="620" y="155" text-anchor="middle" fill="#e0e0e8" font-size="10" font-weight="bold">16√ó768</text>
                    </g>

                    <!-- Bottom explanation -->
                    <g>
                        <rect x="50" y="330" width="300" height="50" fill="#12121a" stroke="#2a2a3e" stroke-width="1" rx="4"/>
                        <text x="60" y="350" fill="#00d2ff" font-weight="bold">Original:</text>
                        <text x="60" y="365" fill="#8888a0" font-size="12">589,824 parameters</text>

                        <rect x="400" y="330" width="300" height="50" fill="#12121a" stroke="#2a2a3e" stroke-width="1" rx="4"/>
                        <text x="410" y="350" fill="#6c63ff" font-weight="bold">With LoRA (rank=16):</text>
                        <text x="410" y="365" fill="#8888a0" font-size="12">24,576 parameters (4.2% of original)</text>
                    </g>
                </svg>
            </div>

            <h3>Parameter Savings Calculator</h3>
            <div class="interactive-container">
                <div style="margin-bottom: 2rem;">
                    <div class="slider-label">
                        <span>Model Size:</span>
                        <span class="slider-value" id="model-size-display">7B</span>
                    </div>
                    <input type="range" min="0" max="4" step="1" value="0" onchange="updateLoraCalc(this.value)" oninput="updateLoraCalc(this.value)">
                    <small style="color: #8888a0;">7B ‚Üí 13B ‚Üí 70B ‚Üí 175B ‚Üí 405B parameters</small>
                </div>

                <div style="margin-bottom: 2rem;">
                    <div class="slider-label">
                        <span>LoRA Rank:</span>
                        <span class="slider-value" id="lora-rank-display">8</span>
                    </div>
                    <input type="range" min="3" max="64" step="1" value="8" onchange="updateLoraCalc(this.value)" oninput="updateLoraCalc(this.value)">
                </div>

                <div style="background: #12121a; border: 1px solid #2a2a3e; border-radius: 8px; padding: 1.5rem; margin-top: 2rem;">
                    <div style="margin-bottom: 1.5rem;">
                        <span style="color: #8888a0;">Full Model Parameters:</span>
                        <span style="color: #00d2ff; font-weight: bold; font-size: 1.2rem;" id="full-params">7B</span>
                    </div>

                    <div style="margin-bottom: 1.5rem;">
                        <span style="color: #8888a0;">LoRA Parameters (Trainable):</span>
                        <span style="color: #6c63ff; font-weight: bold; font-size: 1.2rem;" id="lora-params">3.7M</span>
                    </div>

                    <div>
                        <span style="color: #8888a0;">Percentage of Model:</span>
                        <span style="color: #ff6b6b; font-weight: bold; font-size: 1.2rem;" id="lora-percent">0.05%</span>
                    </div>
                </div>

                <div class="card" style="margin-top: 1.5rem;">
                    <div class="card-title">Why This Matters</div>
                    <div class="card-text">
                        You can fine-tune a 175B parameter model with only 4.7M trainable parameters. This means:<br/>
                        ‚Ä¢ Fits on single GPU<br/>
                        ‚Ä¢ Fast training (hours, not weeks)<br/>
                        ‚Ä¢ Easy distribution and deployment<br/>
                        ‚Ä¢ Performance nearly matches full fine-tuning
                    </div>
                </div>
            </div>

            <h3>How LoRA is Injected</h3>
            <svg width="100%" height="280" viewBox="0 0 600 280" style="max-width: 100%;">
                <text x="300" y="25" text-anchor="middle" fill="#e0e0e8" font-size="14" font-weight="bold">LoRA Injection in Transformer</text>

                <!-- Attention head box -->
                <g>
                    <rect x="50" y="60" width="500" height="200" fill="#12121a" stroke="#2a2a3e" stroke-width="2" rx="8"/>

                    <!-- Input -->
                    <circle cx="100" cy="110" r="15" fill="#6c63ff" stroke="#6c63ff" stroke-width="2"/>
                    <text x="100" y="115" text-anchor="middle" fill="white" font-size="10" font-weight="bold">x</text>

                    <!-- Query projection (with LoRA) -->
                    <rect x="140" y="95" width="80" height="30" fill="#1a1a2e" stroke="#00d2ff" stroke-width="2" rx="4"/>
                    <text x="180" y="120" text-anchor="middle" fill="#00d2ff" font-size="11" font-weight="bold">W_q + B_q¬∑A_q</text>

                    <!-- Key projection (with LoRA) -->
                    <rect x="140" y="135" width="80" height="30" fill="#1a1a2e" stroke="#00d2ff" stroke-width="2" rx="4"/>
                    <text x="180" y="160" text-anchor="middle" fill="#00d2ff" font-size="11" font-weight="bold">W_k + B_k¬∑A_k</text>

                    <!-- Value projection (with LoRA) -->
                    <rect x="140" y="175" width="80" height="30" fill="#1a1a2e" stroke="#00d2ff" stroke-width="2" rx="4"/>
                    <text x="180" y="200" text-anchor="middle" fill="#00d2ff" font-size="11" font-weight="bold">W_v + B_v¬∑A_v</text>

                    <!-- Attention mechanism -->
                    <g>
                        <path d="M 220 110 Q 280 130 340 110" stroke="#6c63ff" stroke-width="2" fill="none" opacity="0.6"/>
                        <path d="M 220 150 Q 280 130 340 150" stroke="#6c63ff" stroke-width="2" fill="none" opacity="0.6"/>
                        <path d="M 220 190 Q 280 130 340 190" stroke="#6c63ff" stroke-width="2" fill="none" opacity="0.6"/>
                        <text x="280" y="90" text-anchor="middle" fill="#6c63ff" font-size="11" font-weight="bold">Attention</text>
                    </g>

                    <!-- Output projection (with LoRA) -->
                    <rect x="360" y="145" width="80" height="30" fill="#1a1a2e" stroke="#00d2ff" stroke-width="2" rx="4"/>
                    <text x="400" y="170" text-anchor="middle" fill="#00d2ff" font-size="11" font-weight="bold">W_o + B_o¬∑A_o</text>

                    <!-- Output -->
                    <circle cx="500" cy="160" r="15" fill="#ff6b6b" stroke="#ff6b6b" stroke-width="2"/>
                    <text x="500" y="165" text-anchor="middle" fill="white" font-size="10" font-weight="bold">y</text>
                </g>

                <text x="300" y="270" text-anchor="middle" fill="#8888a0" font-size="12">LoRA matrices (B, A) are injected in parallel with existing weights</text>
            </svg>
        </section>

        <!-- Fine-Tuning Strategies Comparison -->
        <section class="section scroll-fade">
            <h2>Comparing Fine-Tuning Strategies</h2>
            <p>
                Each strategy has tradeoffs. Choose based on your dataset size, compute, and performance needs.
            </p>

            <div style="overflow-x: auto;">
                <table class="comparison-table">
                    <thead>
                        <tr>
                            <th>Strategy</th>
                            <th>Trainable Params</th>
                            <th>Memory</th>
                            <th>Speed</th>
                            <th>Performance</th>
                            <th>Best For</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>Full Fine-Tuning</strong></td>
                            <td>100%</td>
                            <td>High</td>
                            <td>Slow</td>
                            <td>Excellent</td>
                            <td>Large datasets, unlimited compute</td>
                        </tr>
                        <tr>
                            <td><strong>Feature Extraction</strong></td>
                            <td>~0.5%</td>
                            <td>Low</td>
                            <td>Very Fast</td>
                            <td>Good</td>
                            <td>Small datasets, quick experiments</td>
                        </tr>
                        <tr>
                            <td><strong>LoRA</strong></td>
                            <td>0.1-1%</td>
                            <td>Very Low</td>
                            <td>Fast</td>
                            <td>Excellent</td>
                            <td>Modern production use-cases</td>
                        </tr>
                        <tr>
                            <td><strong>Prefix Tuning</strong></td>
                            <td>0.1%</td>
                            <td>Very Low</td>
                            <td>Fast</td>
                            <td>Very Good</td>
                            <td>Prompt-based adaptation</td>
                        </tr>
                        <tr>
                            <td><strong>Adapters</strong></td>
                            <td>1-2%</td>
                            <td>Low</td>
                            <td>Fast</td>
                            <td>Good-Excellent</td>
                            <td>Multiple task adaptation</td>
                        </tr>
                    </tbody>
                </table>
            </div>

            <h3>Interactive Strategy Explorer</h3>
            <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 1.5rem; margin: 2rem 0;">
                <div class="card" onclick="highlightStrategy('lora')" style="cursor: pointer; border: 2px solid transparent; transition: all 0.3s;">
                    <div class="card-title">LoRA (Recommended)</div>
                    <svg width="100%" height="120" viewBox="0 0 300 120" style="margin: 1rem 0;">
                        <rect x="10" y="10" width="280" height="100" fill="#12121a" stroke="#6c63ff" stroke-width="2" rx="4"/>
                        <text x="150" y="35" text-anchor="middle" fill="#00d2ff" font-size="13" font-weight="bold">Adapter Layers</text>
                        <circle cx="80" cy="70" r="20" fill="#1a1a2e" stroke="#6c63ff" stroke-width="2"/>
                        <text x="80" y="75" text-anchor="middle" fill="#6c63ff" font-size="11" font-weight="bold">B√óA</text>
                        <circle cx="150" cy="70" r="20" fill="#1a1a2e" stroke="#6c63ff" stroke-width="2"/>
                        <text x="150" y="75" text-anchor="middle" fill="#6c63ff" font-size="11" font-weight="bold">B√óA</text>
                        <circle cx="220" cy="70" r="20" fill="#1a1a2e" stroke="#6c63ff" stroke-width="2"/>
                        <text x="220" y="75" text-anchor="middle" fill="#6c63ff" font-size="11" font-weight="bold">B√óA</text>
                    </svg>
                </div>

                <div class="card" onclick="highlightStrategy('prefix')" style="cursor: pointer; border: 2px solid transparent; transition: all 0.3s;">
                    <div class="card-title">Prefix Tuning</div>
                    <svg width="100%" height="120" viewBox="0 0 300 120" style="margin: 1rem 0;">
                        <rect x="10" y="10" width="280" height="100" fill="#12121a" stroke="#ffbb00" stroke-width="2" rx="4"/>
                        <text x="150" y="35" text-anchor="middle" fill="#ffbb00" font-size="13" font-weight="bold">Prefix Vectors</text>
                        <rect x="40" y="55" width="60" height="30" fill="#1a1a2e" stroke="#ffbb00" stroke-width="2" rx="4"/>
                        <text x="70" y="75" text-anchor="middle" fill="#ffbb00" font-size="11" font-weight="bold">Prefix</text>
                        <rect x="130" y="55" width="200" height="30" fill="#2a2a3e" stroke="#8888a0" stroke-width="2" rx="4" opacity="0.5"/>
                        <text x="230" y="75" text-anchor="middle" fill="#8888a0" font-size="11" font-weight="bold">Frozen Model</text>
                    </svg>
                </div>
            </div>
        </section>

        <!-- Data Preparation -->
        <section class="section scroll-fade">
            <h2>Data Preparation for Fine-Tuning</h2>
            <p>
                Fine-tuning requires input-output pairs formatted consistently. Let's look at examples across different tasks.
            </p>

            <div class="interactive-container">
                <div class="tabs">
                    <button class="tab-btn active" onclick="switchTab(event, 'sentiment')">Sentiment</button>
                    <button class="tab-btn" onclick="switchTab(event, 'ner')">NER</button>
                    <button class="tab-btn" onclick="switchTab(event, 'translation')">Translation</button>
                    <button class="tab-btn" onclick="switchTab(event, 'qa')">Q&A</button>
                </div>

                <!-- Sentiment Tab -->
                <div id="sentiment" class="tab-content active">
                    <h3>Sentiment Classification</h3>
                    <div class="example-grid">
                        <div class="example-card">
                            <div class="example-label">Example 1</div>
                            <div class="example-text">Input: "This movie was absolutely wonderful!"
Output: positive</div>
                        </div>
                        <div class="example-card">
                            <div class="example-label">Example 2</div>
                            <div class="example-text">Input: "Terrible product, broke after 2 days"
Output: negative</div>
                        </div>
                        <div class="example-card">
                            <div class="example-label">Example 3</div>
                            <div class="example-text">Input: "The book was okay, nothing special"
Output: neutral</div>
                        </div>
                        <div class="example-card">
                            <div class="example-label">Tokenized</div>
                            <div class="example-text">[CLS] This movie was wonderful [SEP]
‚Üì (encode to embeddings)
[101, 2054, 3185, 2001, 3376, 102]</div>
                        </div>
                    </div>
                </div>

                <!-- NER Tab -->
                <div id="ner" class="tab-content">
                    <h3>Named Entity Recognition</h3>
                    <div class="example-grid">
                        <div class="example-card">
                            <div class="example-label">Example 1</div>
                            <div class="example-text">Text: "Apple CEO Tim Cook"
Entities:
- Apple (ORG)
- Tim Cook (PERSON)</div>
                        </div>
                        <div class="example-card">
                            <div class="example-label">Example 2</div>
                            <div class="example-text">Text: "Paris, France has 2M people"
Entities:
- Paris (LOC)
- France (LOC)</div>
                        </div>
                        <div class="example-card">
                            <div class="example-label">Example 3</div>
                            <div class="example-text">Text: "Microsoft released AI tool"
Entities:
- Microsoft (ORG)
- AI (CONCEPT)</div>
                        </div>
                        <div class="example-card">
                            <div class="example-label">BIO Format</div>
                            <div class="example-text">B-ORG: Apple
O: CEO
B-PERSON: Tim
I-PERSON: Cook</div>
                        </div>
                    </div>
                </div>

                <!-- Translation Tab -->
                <div id="translation" class="tab-content">
                    <h3>Translation (English ‚Üí Ancient Language)</h3>
                    <div class="example-grid">
                        <div class="example-card">
                            <div class="example-label">Example 1</div>
                            <div class="example-text">English: "The sun rises"
Translated: "Sol oritur in oriente"</div>
                        </div>
                        <div class="example-card">
                            <div class="example-label">Example 2</div>
                            <div class="example-text">English: "Knowledge is power"
Translated: "Scientia est potentia"</div>
                        </div>
                        <div class="example-card">
                            <div class="example-label">Example 3</div>
                            <div class="example-text">English: "The wise man speaks"
Translated: "Vir sapiens loquitur"</div>
                        </div>
                        <div class="example-card">
                            <div class="example-label">Format</div>
                            <div class="example-text">"en": "The sun rises",
"la": "Sol oritur in oriente",
"type": "translation"</div>
                        </div>
                    </div>
                </div>

                <!-- QA Tab -->
                <div id="qa" class="tab-content">
                    <h3>Question Answering</h3>
                    <div class="example-grid">
                        <div class="example-card">
                            <div class="example-label">Example 1</div>
                            <div class="example-text">Context: "Python is a language"
Question: "What is Python?"
Answer: "a language"</div>
                        </div>
                        <div class="example-card">
                            <div class="example-label">Example 2</div>
                            <div class="example-text">Context: "Paris is in France"
Question: "Where is Paris?"
Answer: "France"</div>
                        </div>
                        <div class="example-card">
                            <div class="example-label">Example 3</div>
                            <div class="example-text">Context: "AI was founded in 1956"
Question: "When was AI founded?"
Answer: "1956"</div>
                        </div>
                        <div class="example-card">
                            <div class="example-label">SQuAD Format</div>
                            <div class="example-text">{
  "context": "...",
  "question": "...",
  "answer": "...",
  "answer_start": 0
}</div>
                        </div>
                    </div>
                </div>
            </div>

            <h3>Best Practices</h3>
            <div class="example-grid">
                <div class="card">
                    <div class="card-title">Data Quality</div>
                    <div class="card-text">
                        ‚Ä¢ Consistent formatting<br/>
                        ‚Ä¢ No duplicates<br/>
                        ‚Ä¢ Balanced classes (for classification)<br/>
                        ‚Ä¢ Representative of real data
                    </div>
                </div>
                <div class="card">
                    <div class="card-title">Data Size</div>
                    <div class="card-text">
                        ‚Ä¢ Feature extraction: 100-1K examples<br/>
                        ‚Ä¢ LoRA: 500-10K examples<br/>
                        ‚Ä¢ Full fine-tuning: 5K-100K+ examples
                    </div>
                </div>
                <div class="card">
                    <div class="card-title">Train/Val/Test</div>
                    <div class="card-text">
                        ‚Ä¢ Split: 80% train / 10% val / 10% test<br/>
                        ‚Ä¢ Use validation set for early stopping<br/>
                        ‚Ä¢ Evaluate on held-out test set
                    </div>
                </div>
            </div>
        </section>

        <!-- Catastrophic Forgetting -->
        <section class="section scroll-fade">
            <h2>Avoiding Catastrophic Forgetting</h2>
            <p>
                A major risk in fine-tuning: the model "forgets" knowledge from pre-training while adapting to the new task. Use the slider to see the tradeoff.
            </p>

            <div class="interactive-container">
                <div class="slider-label">
                    <span>Fine-tuning Intensity:</span>
                    <span class="slider-value" id="forgetting-slider-value">Light</span>
                </div>
                <input type="range" min="0" max="100" value="50" onchange="updateForgetting(this.value)" oninput="updateForgetting(this.value)" style="margin: 1rem 0;">

                <div class="chart-container" style="margin-top: 2rem;">
                    <canvas id="forgetting-chart" style="width: 100%; height: 100%;"></canvas>
                </div>
            </div>

            <h3>Prevention Strategies</h3>
            <div class="example-grid">
                <div class="card">
                    <div class="card-title">Small Learning Rate</div>
                    <div class="card-text">
                        Keep updates conservative. Typical range: 1e-5 to 5e-5 for fine-tuning.
                    </div>
                </div>
                <div class="card">
                    <div class="card-title">Early Stopping</div>
                    <div class="card-text">
                        Monitor validation loss. Stop if it stops improving for N epochs.
                    </div>
                </div>
                <div class="card">
                    <div class="card-title">Regularization</div>
                    <div class="card-text">
                        L2 regularization penalizes large weight changes, keeping the model close to pre-trained weights.
                    </div>
                </div>
                <div class="card">
                    <div class="card-title">LoRA</div>
                    <div class="card-text">
                        By only updating small adapter matrices, the original weights remain frozen, preventing forgetting.
                    </div>
                </div>
            </div>
        </section>

        <!-- Python Code -->
        <section class="section scroll-fade">
            <h2>Complete HuggingFace Fine-Tuning Code</h2>
            <p>
                Here's a production-ready example using HuggingFace Transformers and Accelerate.
            </p>

            <div class="code-block">
                <pre><code><span class="code-comment"># Install: pip install transformers datasets peft torch accelerate</span>

<span class="code-keyword">from</span> transformers <span class="code-keyword">import</span> AutoModelForSequenceClassification, AutoTokenizer, TrainingArguments, Trainer
<span class="code-keyword">from</span> datasets <span class="code-keyword">import</span> load_dataset
<span class="code-keyword">from</span> peft <span class="code-keyword">import</span> get_peft_model, LoraConfig, TaskType
<span class="code-keyword">import</span> torch

<span class="code-comment"># 1. Load pre-trained model and tokenizer</span>
model_name = <span class="code-string">"bert-base-uncased"</span>
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)

<span class="code-comment"># 2. Setup LoRA (optional, but recommended)</span>
lora_config = LoraConfig(
    task_type=TaskType.SEQ_CLS,
    r=<span class="code-string">8</span>,                    <span class="code-comment"># LoRA rank</span>
    lora_alpha=<span class="code-string">16</span>,
    lora_dropout=<span class="code-string">0.1</span>,
    bias=<span class="code-string">"none"</span>,
    target_modules=[<span class="code-string">"query"</span>, <span class="code-string">"value"</span>]
)
model = get_peft_model(model, lora_config)

<span class="code-comment"># 3. Load and prepare dataset</span>
dataset = load_dataset(<span class="code-string">"glue"</span>, <span class="code-string">"mrpc"</span>)

<span class="code-keyword">def</span> <span class="code-function">preprocess</span>(examples):
    return tokenizer(
        examples[<span class="code-string">"sentence1"</span>],
        examples[<span class="code-string">"sentence2"</span>],
        truncation=<span class="code-keyword">True</span>,
        max_length=<span class="code-string">128</span>
    )

dataset = dataset.map(<span class="code-function">preprocess</span>, batched=<span class="code-keyword">True</span>)

<span class="code-comment"># 4. Training arguments</span>
training_args = TrainingArguments(
    output_dir=<span class="code-string">"./results"</span>,
    learning_rate=<span class="code-string">5e-5</span>,
    per_device_train_batch_size=<span class="code-string">16</span>,
    per_device_eval_batch_size=<span class="code-string">16</span>,
    num_train_epochs=<span class="code-string">3</span>,
    weight_decay=<span class="code-string">0.01</span>,
    evaluation_strategy=<span class="code-string">"epoch"</span>,
    save_strategy=<span class="code-string">"epoch"</span>,
    load_best_model_at_end=<span class="code-keyword">True</span>,
    metric_for_best_model=<span class="code-string">"accuracy"</span>,
)

<span class="code-comment"># 5. Trainer setup</span>
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=dataset[<span class="code-string">"train"</span>],
    eval_dataset=dataset[<span class="code-string">"validation"</span>],
    tokenizer=tokenizer,
)

<span class="code-comment"># 6. Train</span>
trainer.<span class="code-function">train</span>()

<span class="code-comment"># 7. Evaluate</span>
results = trainer.<span class="code-function">evaluate</span>()
print(<span class="code-string">f"Accuracy: {results['eval_accuracy']:.4f}"</span>)

<span class="code-comment"># 8. Save the adapter (only LoRA weights, not full model)</span>
model.save_pretrained(<span class="code-string">"./lora-adapter"</span>)
tokenizer.save_pretrained(<span class="code-string">"./lora-adapter"</span>)</code></pre>
            </div>

            <h3>Alternative: Feature Extraction (Frozen Backbone)</h3>
            <div class="code-block">
                <pre><code><span class="code-comment"># Skip LoRA setup, just freeze the base model</span>

<span class="code-keyword">for</span> param <span class="code-keyword">in</span> model.bert.parameters():
    param.requires_grad = <span class="code-keyword">False</span>  <span class="code-comment"># Freeze base model</span>

<span class="code-comment"># Only classifier head will be trained</span>
<span class="code-keyword">for</span> param <span class="code-keyword">in</span> model.classifier.parameters():
    param.requires_grad = <span class="code-keyword">True</span>

<span class="code-comment"># Rest of training code remains the same...</span></code></pre>
            </div>

            <h3>Using the Fine-tuned Model</h3>
            <div class="code-block">
                <pre><code><span class="code-keyword">from</span> transformers <span class="code-keyword">import</span> pipeline

<span class="code-comment"># Load your fine-tuned model</span>
classifier = pipeline(
    <span class="code-string">"text-classification"</span>,
    model=<span class="code-string">"./results/checkpoint-best"</span>,
    tokenizer=<span class="code-string">"./results/checkpoint-best"</span>
)

<span class="code-comment"># Make predictions</span>
result = classifier(<span class="code-string">"This movie is amazing!"</span>)
print(result)  <span class="code-comment"># [{'label': 'POSITIVE', 'score': 0.98}]</span></code></pre>
            </div>
        </section>

        <!-- Ancient Language Translation -->
        <section class="section scroll-fade">
            <h2>Fine-Tuning for Ancient Language Translation</h2>
            <p>
                Let's apply fine-tuning specifically to translating English to ancient languages (Latin, Ancient Greek, etc.). This is a challenging but fascinating task.
            </p>

            <h3>Challenges and Considerations</h3>
            <div class="example-grid">
                <div class="card">
                    <div class="card-title">Limited Data</div>
                    <div class="card-text">
                        Ancient language corpora are small. Typical translation pairs: hundreds to thousands, not millions. This calls for LoRA or feature extraction.
                    </div>
                </div>
                <div class="card">
                    <div class="card-title">Terminology</div>
                    <div class="card-text">
                        Ancient languages lack terms for modern concepts. You'll need to use circumlocutions or create neologisms.
                    </div>
                </div>
                <div class="card">
                    <div class="card-title">Grammar Complexity</div>
                    <div class="card-text">
                        Latin, Greek, Sanskrit have rich morphological systems. Inflections are crucial for meaning.
                    </div>
                </div>
                <div class="card">
                    <div class="card-title">Model Choice</div>
                    <div class="card-text">
                        mBART, mT5, or multilingual models work better than English-only models. They already understand multiple languages.
                    </div>
                </div>
            </div>

            <h3>Data Preparation</h3>
            <p>
                Start with digitized ancient texts, translations, and scholarly resources. Sources include:
            </p>
            <ul style="margin: 1rem 0; margin-left: 2rem; color: #c8c8d0;">
                <li>Perseus Digital Library (Greek & Latin texts)</li>
                <li>Ancient Text Translation Projects</li>
                <li>Bilingual parallel corpora from academic sources</li>
                <li>Translation manuals and examples from scholars</li>
            </ul>

            <h3>Example Fine-Tuning Script for Translation</h3>
            <div class="code-block">
                <pre><code><span class="code-keyword">from</span> transformers <span class="code-keyword">import</span> AutoModelForSeq2SeqLM, AutoTokenizer, Seq2SeqTrainingArguments, Seq2SeqTrainer
<span class="code-keyword">from</span> datasets <span class="code-keyword">import</span> load_dataset
<span class="code-keyword">from</span> peft <span class="code-keyword">import</span> get_peft_model, LoraConfig, TaskType

<span class="code-comment"># Use multilingual model</span>
model_name = <span class="code-string">"facebook/mbart-large-cc25"</span>
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSeq2SeqLM.from_pretrained(model_name)

<span class="code-comment"># Setup LoRA for translation</span>
lora_config = LoraConfig(
    task_type=TaskType.SEQ_2_SEQ_LM,
    r=<span class="code-string">16</span>,
    lora_alpha=<span class="code-string">32</span>,
    lora_dropout=<span class="code-string">0.05</span>,
    bias=<span class="code-string">"none"</span>,
    target_modules=[<span class="code-string">"k_proj"</span>, <span class="code-string">"q_proj"</span>, <span class="code-string">"v_proj"</span>]
)
model = get_peft_model(model, lora_config)

<span class="code-comment"># Load translation pairs (English -> Latin)</span>
<span class="code-keyword">with</span> open(<span class="code-string">"en_la_pairs.json"</span>) <span class="code-keyword">as</span> f:
    data = json.load(f)

<span class="code-keyword">def</span> <span class="code-function">preprocess_translation</span>(examples):
    inputs = [ex[<span class="code-string">"en"</span>] <span class="code-keyword">for</span> ex <span class="code-keyword">in</span> examples]
    targets = [ex[<span class="code-string">"la"</span>] <span class="code-keyword">for</span> ex <span class="code-keyword">in</span> examples]

    model_inputs = tokenizer(
        inputs,
        text_target=targets,
        max_length=<span class="code-string">256</span>,
        truncation=<span class="code-keyword">True</span>
    )
    <span class="code-keyword">return</span> model_inputs

<span class="code-comment"># Training (with small LR, early stopping)</span>
training_args = Seq2SeqTrainingArguments(
    output_dir=<span class="code-string">"./en-la-translator"</span>,
    learning_rate=<span class="code-string">2e-4</span>,  <span class="code-comment"># Conservative for small dataset</span>
    per_device_train_batch_size=<span class="code-string">8</span>,
    num_train_epochs=<span class="code-string">10</span>,
    weight_decay=<span class="code-string">0.01</span>,
    evaluation_strategy=<span class="code-string">"epoch"</span>,
    save_best_model=<span class="code-keyword">True</span>,
    load_best_model_at_end=<span class="code-keyword">True</span>,
)

trainer = Seq2SeqTrainer(
    model=model,
    args=training_args,
    train_dataset=dataset[<span class="code-string">"train"</span>],
    eval_dataset=dataset[<span class="code-string">"validation"</span>],
)

trainer.<span class="code-function">train</span>()</code></pre>
            </div>

            <h3>Realistic Expectations</h3>
            <div class="card">
                <div class="card-title">With Small Datasets (100-500 pairs)</div>
                <div class="card-text">
                    ‚Ä¢ Model learns basic patterns but struggles with rare words<br/>
                    ‚Ä¢ Requires post-processing and manual corrections<br/>
                    ‚Ä¢ Best for assisting humans, not standalone translation<br/>
                    ‚Ä¢ BLEU score typically 15-25
                </div>
            </div>

            <div class="card" style="margin-top: 1.5rem;">
                <div class="card-title">With Moderate Datasets (1000-5000 pairs)</div>
                <div class="card-text">
                    ‚Ä¢ Handles common phrases reasonably well<br/>
                    ‚Ä¢ Still needs human review for nuance and grammar<br/>
                    ‚Ä¢ Good for speeding up translation workflow<br/>
                    ‚Ä¢ BLEU score typically 25-35
                </div>
            </div>

            <div class="card" style="margin-top: 1.5rem;">
                <div class="card-title">Best Practices</div>
                <div class="card-text">
                    ‚Ä¢ Use domain-specific terminology lists<br/>
                    ‚Ä¢ Create validation set with expert translations<br/>
                    ‚Ä¢ Consider ensemble with rule-based systems<br/>
                    ‚Ä¢ Implement beam search for better diversity<br/>
                    ‚Ä¢ Use back-translation for data augmentation
                </div>
            </div>
        </section>

        <!-- Footer Navigation -->
        <section class="nav-footer scroll-fade">
            <a href="08-gpt.html">‚Üê Previous: Large Language Models</a>
            <a href="index.html" style="margin-left: auto; margin-right: auto;">Index</a>
            <a href="10-project.html" class="next">Hands-On Project ‚Üí</a>
        </section>
    </div>

    <script>
        // Scroll-triggered fade-in animations
        const observerOptions = {
            threshold: 0.1,
            rootMargin: '0px 0px -50px 0px'
        };

        const observer = new IntersectionObserver((entries) => {
            entries.forEach(entry => {
                if (entry.isIntersecting) {
                    entry.target.classList.add('visible');
                    observer.unobserve(entry.target);
                }
            });
        }, observerOptions);

        document.querySelectorAll('.scroll-fade').forEach(el => {
            observer.observe(el);
        });

        // Strategy Toggle
        function switchStrategy(strategy) {
            document.querySelectorAll('[id$="-strategy"]').forEach(el => {
                el.style.display = 'none';
            });
            document.getElementById(strategy + '-strategy').style.display = 'block';

            document.querySelectorAll('.toggle-btn').forEach(btn => {
                btn.classList.remove('active');
            });
            event.target.classList.add('active');
        }

        // Learning Rate Chart
        function updateLearningRate(value) {
            const lr = Math.pow(10, parseFloat(value));
            const formattedLr = lr < 0.0001 ? `${(lr * 1e5).toFixed(0)}e-5` : `${(lr * 1e3).toFixed(1)}e-3`;
            document.getElementById('lr-value').textContent = formattedLr;

            const canvas = document.getElementById('loss-chart');
            if (canvas && canvas.getContext) {
                drawLearningRateChart(canvas, parseFloat(value));
            }
        }

        function drawLearningRateChart(canvas, lrLog) {
            const ctx = canvas.getContext('2d');
            const width = canvas.parentElement.clientWidth;
            const height = canvas.parentElement.clientHeight;

            canvas.width = width;
            canvas.height = height;

            // Clear canvas
            ctx.fillStyle = '#12121a';
            ctx.fillRect(0, 0, width, height);

            // Draw axes
            ctx.strokeStyle = '#2a2a3e';
            ctx.lineWidth = 2;
            ctx.beginPath();
            ctx.moveTo(60, 20);
            ctx.lineTo(60, height - 40);
            ctx.lineTo(width - 20, height - 40);
            ctx.stroke();

            // Labels
            ctx.fillStyle = '#8888a0';
            ctx.font = '12px system-ui';
            ctx.textAlign = 'center';
            ctx.fillText('Epochs', width / 2, height - 10);
            ctx.save();
            ctx.translate(15, height / 2);
            ctx.rotate(-Math.PI / 2);
            ctx.fillText('Loss', 0, 0);
            ctx.restore();

            // Draw curves
            const epochs = 30;
            const padding = 60;
            const graphWidth = width - padding - 20;
            const graphHeight = height - padding;

            // Generate loss curves based on learning rate
            const lr = Math.pow(10, lrLog);

            // Too high LR (diverges)
            ctx.strokeStyle = '#ff6b6b';
            ctx.lineWidth = 2;
            ctx.beginPath();
            for (let i = 0; i <= epochs; i++) {
                const x = padding + (i / epochs) * graphWidth;
                const divergence = Math.exp(i / 3) * 0.1;
                const y = height - padding + divergence * graphHeight;
                if (i === 0) ctx.moveTo(x, y);
                else ctx.lineTo(x, Math.min(y, height - padding + 100));
            }
            if (lrLog > -3.2) ctx.stroke();

            // Too low LR (slow)
            ctx.strokeStyle = '#ffbb00';
            ctx.lineWidth = 2;
            ctx.beginPath();
            for (let i = 0; i <= epochs; i++) {
                const x = padding + (i / epochs) * graphWidth;
                const decay = 3 * Math.exp(-i / 15);
                const y = height - padding - decay * graphHeight * 0.7;
                if (i === 0) ctx.moveTo(x, y);
                else ctx.lineTo(x, y);
            }
            if (lrLog < -4.5) ctx.stroke();

            // Just right (smooth convergence)
            ctx.strokeStyle = '#00d2ff';
            ctx.lineWidth = 3;
            ctx.beginPath();
            for (let i = 0; i <= epochs; i++) {
                const x = padding + (i / epochs) * graphWidth;
                const decay = 2.5 * Math.exp(-i / 8);
                const y = height - padding - decay * graphHeight * 0.85;
                if (i === 0) ctx.moveTo(x, y);
                else ctx.lineTo(x, y);
            }
            if (lrLog >= -4.5 && lrLog <= -3.2) ctx.stroke();

            // Legend
            ctx.fillStyle = '#ff6b6b';
            ctx.fillRect(width - 180, 20, 12, 12);
            ctx.fillStyle = '#8888a0';
            ctx.font = '11px system-ui';
            ctx.textAlign = 'left';
            ctx.fillText('Too High', width - 165, 28);

            ctx.fillStyle = '#ffbb00';
            ctx.fillRect(width - 180, 45, 12, 12);
            ctx.fillText('Too Low', width - 165, 53);

            ctx.fillStyle = '#00d2ff';
            ctx.fillRect(width - 180, 70, 12, 12);
            ctx.fillText('Just Right', width - 165, 78);
        }

        // LoRA Calculator
        function updateLoraCalc(value) {
            const modelSizes = [7, 13, 70, 175, 405];
            const ranks = [3, 4, 8, 16, 32, 64];

            // Get slider values
            const modelSlider = document.querySelector('input[type="range"][min="0"][max="4"]');
            const rankSlider = document.querySelector('input[type="range"][min="3"][max="64"]');

            if (!modelSlider || !rankSlider) return;

            const modelIdx = parseInt(modelSlider.value);
            const rank = parseInt(rankSlider.value);

            const modelSize = modelSizes[modelIdx];
            const loraParamCount = modelSize * 1e9 * 2 * rank / (rank + modelSize);
            const percentage = (loraParamCount / (modelSize * 1e9)) * 100;

            // Update display
            document.getElementById('model-size-display').textContent = modelSize + 'B';
            document.getElementById('lora-rank-display').textContent = rank;
            document.getElementById('full-params').textContent = modelSize + 'B';
            document.getElementById('lora-params').textContent = (loraParamCount / 1e6).toFixed(1) + 'M';
            document.getElementById('lora-percent').textContent = percentage.toFixed(2) + '%';
        }

        // Tab switching
        function switchTab(e, tabName) {
            document.querySelectorAll('.tab-content').forEach(tab => {
                tab.classList.remove('active');
            });
            document.querySelectorAll('.tab-btn').forEach(btn => {
                btn.classList.remove('active');
            });

            document.getElementById(tabName).classList.add('active');
            e.target.classList.add('active');
        }

        // Catastrophic Forgetting visualization
        function updateForgetting(value) {
            const intensity = parseInt(value);
            let label = 'Light';
            if (intensity < 33) label = 'Light';
            else if (intensity < 67) label = 'Moderate';
            else label = 'Severe';

            document.getElementById('forgetting-slider-value').textContent = label;

            const canvas = document.getElementById('forgetting-chart');
            if (canvas && canvas.getContext) {
                drawForgettingChart(canvas, intensity);
            }
        }

        function drawForgettingChart(canvas, intensity) {
            const ctx = canvas.getContext('2d');
            const width = canvas.parentElement.clientWidth;
            const height = canvas.parentElement.clientHeight;

            canvas.width = width;
            canvas.height = height;

            // Clear
            ctx.fillStyle = '#12121a';
            ctx.fillRect(0, 0, width, height);

            // Axes
            ctx.strokeStyle = '#2a2a3e';
            ctx.lineWidth = 2;
            ctx.beginPath();
            ctx.moveTo(60, 20);
            ctx.lineTo(60, height - 40);
            ctx.lineTo(width - 20, height - 40);
            ctx.stroke();

            // Labels
            ctx.fillStyle = '#8888a0';
            ctx.font = '12px system-ui';
            ctx.textAlign = 'center';
            ctx.fillText('Training Epochs', width / 2, height - 10);

            // New task performance (goes up)
            ctx.strokeStyle = '#00d2ff';
            ctx.lineWidth = 3;
            ctx.beginPath();
            const padding = 60;
            const graphWidth = width - padding - 20;
            const graphHeight = height - padding;

            for (let i = 0; i <= 30; i++) {
                const x = padding + (i / 30) * graphWidth;
                const progress = Math.min(1, i / 10 + Math.random() * 0.1);
                const y = height - padding - progress * graphHeight * 0.8;
                if (i === 0) ctx.moveTo(x, y);
                else ctx.lineTo(x, y);
            }
            ctx.stroke();

            // Original task performance (goes down based on intensity)
            ctx.strokeStyle = '#ff6b6b';
            ctx.lineWidth = 3;
            ctx.beginPath();

            for (let i = 0; i <= 30; i++) {
                const x = padding + (i / 30) * graphWidth;
                const forgetting = (intensity / 100) * Math.pow(i / 30, 1.5);
                const y = height - padding - (0.8 - forgetting * 0.8) * graphHeight;
                if (i === 0) ctx.moveTo(x, y);
                else ctx.lineTo(x, y);
            }
            ctx.stroke();

            // Legend
            ctx.fillStyle = '#00d2ff';
            ctx.fillRect(width - 200, 20, 12, 12);
            ctx.fillStyle = '#8888a0';
            ctx.font = '11px system-ui';
            ctx.textAlign = 'left';
            ctx.fillText('New Task Performance', width - 185, 28);

            ctx.fillStyle = '#ff6b6b';
            ctx.fillRect(width - 200, 45, 12, 12);
            ctx.fillText('Original Task Performance', width - 185, 53);
        }

        // Initialize charts
        updateLearningRate('-5');
        updateLoraCalc('0');
        updateForgetting('50');

        // Responsive chart redrawing
        window.addEventListener('resize', () => {
            updateLearningRate(document.querySelector('input[type="range"][min="-5"][max="-3"]').value);
            updateForgetting(document.querySelector('input[type="range"][min="0"][max="100"]').value);
        });
    </script>
</body>
</html>
