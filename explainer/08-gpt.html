<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Module 08: GPT - Interactive NLP Course</title>
  <style>
    * {
      margin: 0;
      padding: 0;
      box-sizing: border-box;
    }

    html {
      scroll-behavior: smooth;
    }

    body {
      font-family: 'Inter', system-ui, -apple-system, sans-serif;
      background: #0a0a0f;
      color: #e0e0e8;
      line-height: 1.6;
    }

    /* Sticky Navigation Bar */
    nav {
      position: sticky;
      top: 0;
      background: rgba(10, 10, 15, 0.95);
      backdrop-filter: blur(10px);
      border-bottom: 1px solid #2a2a3e;
      padding: 1rem 2rem;
      z-index: 100;
      display: flex;
      align-items: center;
      gap: 1rem;
    }

    nav a {
      color: #6c63ff;
      text-decoration: none;
      font-weight: 500;
      display: flex;
      align-items: center;
      gap: 0.5rem;
      transition: color 0.3s ease;
    }

    nav a:hover {
      color: #00d2ff;
    }

    nav .title {
      flex: 1;
      color: #8888a0;
      font-size: 0.9rem;
    }

    /* Containers */
    .container {
      max-width: 900px;
      margin: 0 auto;
      padding: 2rem;
    }

    /* Hero Section */
    .hero {
      text-align: center;
      padding: 4rem 2rem;
      background: linear-gradient(135deg, #1a1a2e 0%, #12121a 100%);
      border-radius: 12px;
      margin-bottom: 3rem;
      border: 1px solid #2a2a3e;
      animation: fadeInUp 0.8s ease-out;
    }

    .hero h1 {
      font-size: 2.5rem;
      margin-bottom: 0.5rem;
      background: linear-gradient(135deg, #6c63ff, #00d2ff);
      -webkit-background-clip: text;
      -webkit-text-fill-color: transparent;
      background-clip: text;
    }

    .hero p {
      font-size: 1.1rem;
      color: #8888a0;
      margin-bottom: 1rem;
    }

    .hero .meta {
      display: flex;
      justify-content: center;
      gap: 2rem;
      color: #8888a0;
      font-size: 0.9rem;
      flex-wrap: wrap;
    }

    /* Section Styles */
    section {
      margin-bottom: 3rem;
      opacity: 0;
      animation: fadeInUp 0.8s ease-out forwards;
    }

    @keyframes fadeInUp {
      from {
        opacity: 0;
        transform: translateY(20px);
      }
      to {
        opacity: 1;
        transform: translateY(0);
      }
    }

    section:nth-child(2) { animation-delay: 0.1s; }
    section:nth-child(3) { animation-delay: 0.2s; }
    section:nth-child(4) { animation-delay: 0.3s; }
    section:nth-child(5) { animation-delay: 0.4s; }
    section:nth-child(6) { animation-delay: 0.5s; }
    section:nth-child(7) { animation-delay: 0.6s; }
    section:nth-child(8) { animation-delay: 0.7s; }
    section:nth-child(9) { animation-delay: 0.8s; }
    section:nth-child(10) { animation-delay: 0.9s; }

    h2 {
      font-size: 1.8rem;
      margin-bottom: 1.5rem;
      color: #00d2ff;
      display: flex;
      align-items: center;
      gap: 0.5rem;
    }

    .section-card {
      background: #12121a;
      border: 1px solid #2a2a3e;
      border-radius: 8px;
      padding: 2rem;
      margin-bottom: 1.5rem;
    }

    p, li {
      color: #d0d0d8;
      margin-bottom: 1rem;
    }

    /* Comparison Grid */
    .comparison {
      display: grid;
      grid-template-columns: 1fr 1fr;
      gap: 2rem;
      margin-bottom: 2rem;
    }

    .comparison-card {
      background: #1a1a2e;
      border: 2px solid #2a2a3e;
      border-radius: 8px;
      padding: 1.5rem;
      transition: all 0.3s ease;
    }

    .comparison-card.active {
      border-color: #6c63ff;
      background: rgba(108, 99, 255, 0.05);
    }

    .comparison-card h3 {
      color: #00d2ff;
      margin-bottom: 1rem;
      font-size: 1.2rem;
    }

    .comparison-card ul {
      list-style: none;
      padding-left: 0;
    }

    .comparison-card li {
      padding: 0.5rem 0;
      padding-left: 1.5rem;
      position: relative;
      font-size: 0.95rem;
    }

    .comparison-card li:before {
      content: "‚Üí";
      position: absolute;
      left: 0;
      color: #ff6b6b;
    }

    /* Toggle Button */
    .toggle-btn {
      background: #6c63ff;
      border: none;
      color: white;
      padding: 0.7rem 1.5rem;
      border-radius: 6px;
      cursor: pointer;
      font-weight: 500;
      margin-bottom: 1rem;
      transition: all 0.3s ease;
    }

    .toggle-btn:hover {
      background: #00d2ff;
      transform: translateY(-2px);
    }

    /* Interactive Demo Section */
    .demo-container {
      background: #1a1a2e;
      border: 1px solid #2a2a3e;
      border-radius: 8px;
      padding: 2rem;
      margin-bottom: 1.5rem;
    }

    .prompt-display {
      background: #0a0a0f;
      border: 1px solid #2a2a3e;
      padding: 1.5rem;
      border-radius: 6px;
      margin-bottom: 1.5rem;
      font-family: 'Monaco', 'Courier New', monospace;
      color: #00d2ff;
      font-size: 1rem;
      min-height: 3rem;
      word-break: break-word;
    }

    .tokens-grid {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(80px, 1fr));
      gap: 0.5rem;
      margin-bottom: 1.5rem;
    }

    .token-btn {
      background: #2a2a3e;
      border: 1px solid #3a3a4e;
      color: #d0d0d8;
      padding: 0.7rem;
      border-radius: 4px;
      cursor: pointer;
      font-size: 0.85rem;
      transition: all 0.2s ease;
      white-space: nowrap;
      overflow: hidden;
      text-overflow: ellipsis;
    }

    .token-btn:hover {
      background: #6c63ff;
      color: white;
      transform: scale(1.05);
    }

    .token-btn .prob {
      display: block;
      font-size: 0.7rem;
      color: #8888a0;
    }

    .demo-controls {
      display: flex;
      gap: 1rem;
      margin-bottom: 1.5rem;
      flex-wrap: wrap;
    }

    .slider-group {
      display: flex;
      flex-direction: column;
      gap: 0.5rem;
      flex: 1;
      min-width: 200px;
    }

    .slider-group label {
      font-size: 0.9rem;
      color: #8888a0;
    }

    input[type="range"] {
      width: 100%;
      height: 6px;
      border-radius: 3px;
      background: #2a2a3e;
      outline: none;
      -webkit-appearance: none;
    }

    input[type="range"]::-webkit-slider-thumb {
      -webkit-appearance: none;
      appearance: none;
      width: 18px;
      height: 18px;
      border-radius: 50%;
      background: #6c63ff;
      cursor: pointer;
      transition: all 0.2s ease;
    }

    input[type="range"]::-webkit-slider-thumb:hover {
      background: #00d2ff;
      transform: scale(1.2);
    }

    input[type="range"]::-moz-range-thumb {
      width: 18px;
      height: 18px;
      border-radius: 50%;
      background: #6c63ff;
      cursor: pointer;
      border: none;
    }

    .chart-container {
      background: #0a0a0f;
      border: 1px solid #2a2a3e;
      padding: 1.5rem;
      border-radius: 6px;
      margin-top: 1rem;
    }

    .bar-chart {
      display: flex;
      align-items: flex-end;
      gap: 0.3rem;
      height: 150px;
      margin-top: 1rem;
    }

    .bar {
      flex: 1;
      background: linear-gradient(135deg, #6c63ff, #00d2ff);
      border-radius: 2px 2px 0 0;
      position: relative;
      transition: all 0.3s ease;
      min-width: 15px;
    }

    .bar:hover {
      background: linear-gradient(135deg, #00d2ff, #ff6b6b);
      filter: brightness(1.2);
    }

    .bar-label {
      position: absolute;
      bottom: -20px;
      left: 50%;
      transform: translateX(-50%);
      font-size: 0.7rem;
      color: #8888a0;
      white-space: nowrap;
      width: 100%;
      text-align: center;
      overflow: hidden;
      text-overflow: ellipsis;
    }

    .bar-value {
      position: absolute;
      top: -25px;
      left: 50%;
      transform: translateX(-50%);
      font-size: 0.7rem;
      color: #00d2ff;
      font-weight: 500;
    }

    /* SVG Styles */
    svg {
      width: 100%;
      height: auto;
    }

    .svg-container {
      background: #0a0a0f;
      border: 1px solid #2a2a3e;
      border-radius: 6px;
      padding: 2rem;
      margin-bottom: 1.5rem;
      overflow-x: auto;
    }

    /* Scaling Laws Chart */
    .scaling-controls {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
      gap: 1.5rem;
      margin-bottom: 2rem;
    }

    /* Code Block */
    .code-block {
      background: #0a0a0f;
      border: 1px solid #2a2a3e;
      border-radius: 6px;
      padding: 1.5rem;
      overflow-x: auto;
      margin-bottom: 1.5rem;
    }

    .code-block pre {
      margin: 0;
      font-family: 'Monaco', 'Courier New', monospace;
      font-size: 0.85rem;
      line-height: 1.5;
    }

    .token-keyword { color: #6c63ff; }
    .token-string { color: #00d2ff; }
    .token-comment { color: #8888a0; }
    .token-function { color: #ff6b6b; }
    .token-number { color: #6bcf7f; }

    /* Footer Navigation */
    footer {
      display: grid;
      grid-template-columns: 1fr 1fr;
      gap: 2rem;
      margin-top: 4rem;
      padding: 2rem;
      border-top: 1px solid #2a2a3e;
    }

    footer a {
      padding: 1rem;
      background: #1a1a2e;
      border: 1px solid #2a2a3e;
      border-radius: 6px;
      color: #6c63ff;
      text-decoration: none;
      text-align: center;
      transition: all 0.3s ease;
    }

    footer a:hover {
      background: #6c63ff;
      color: white;
      transform: translateY(-2px);
    }

    /* Responsive */
    @media (max-width: 768px) {
      .container {
        padding: 1rem;
      }

      .hero h1 {
        font-size: 1.8rem;
      }

      .comparison {
        grid-template-columns: 1fr;
      }

      h2 {
        font-size: 1.4rem;
      }

      .hero .meta {
        flex-direction: column;
        gap: 1rem;
      }

      footer {
        grid-template-columns: 1fr;
      }
    }

    /* Sampling Toggles */
    .sampling-toggles {
      display: flex;
      gap: 1rem;
      margin-bottom: 1rem;
      flex-wrap: wrap;
    }

    .toggle-btn.secondary {
      background: #2a2a3e;
      color: #d0d0d8;
    }

    .toggle-btn.secondary.active {
      background: #6c63ff;
      color: white;
    }

    /* Architecture Diagram */
    .arch-box {
      background: #1a1a2e;
      border: 1px solid #2a2a3e;
      padding: 1rem;
      border-radius: 4px;
      margin: 0.5rem 0;
      font-family: monospace;
      font-size: 0.9rem;
    }

    .arch-flow {
      display: flex;
      align-items: center;
      justify-content: space-between;
      margin: 1rem 0;
      flex-wrap: wrap;
      gap: 1rem;
    }

    .arch-flow .arrow {
      color: #6c63ff;
      font-weight: bold;
    }

    /* Few-shot Examples */
    .example-card {
      background: #1a1a2e;
      border-left: 3px solid #6c63ff;
      padding: 1rem;
      margin-bottom: 1rem;
      border-radius: 4px;
    }

    .example-card.input {
      border-left-color: #00d2ff;
    }

    .example-card.output {
      border-left-color: #ff6b6b;
    }

    .example-label {
      font-size: 0.8rem;
      color: #8888a0;
      margin-bottom: 0.5rem;
      text-transform: uppercase;
    }

    /* Status Text */
    .status {
      color: #8888a0;
      font-size: 0.9rem;
      margin-top: 1rem;
    }

    /* Table Styles */
    table {
      width: 100%;
      border-collapse: collapse;
      margin-bottom: 1.5rem;
    }

    th, td {
      padding: 0.8rem;
      text-align: left;
      border-bottom: 1px solid #2a2a3e;
    }

    th {
      background: #1a1a2e;
      color: #00d2ff;
      font-weight: 500;
    }

    tr:hover {
      background: rgba(108, 99, 255, 0.05);
    }
  </style>
</head>
<body>
  <nav>
    <a href="index.html">‚Üê Back to Course</a>
    <span class="title">Module 08: GPT</span>
  </nav>

  <div class="container">
    <!-- Hero Section -->
    <section class="hero">
      <h1>Module 08: GPT</h1>
      <p>Predicting the Next Token at Scale</p>
      <div class="meta">
        <span>üìö Duration: ~25 minutes</span>
        <span>üîó OpenAI 2018‚Äì2023</span>
        <span>üéØ Autoregressive Decoding</span>
      </div>
    </section>

    <!-- BERT vs GPT Section -->
    <section>
      <h2>üîÑ BERT vs GPT: The Key Difference</h2>
      <div class="section-card">
        <button class="toggle-btn" onclick="toggleArchitecture()">Toggle Architecture View</button>
        <div id="archToggle" style="display: grid; grid-template-columns: 1fr 1fr; gap: 1.5rem;">
          <div id="bertCard" class="comparison-card active">
            <h3>BERT</h3>
            <ul>
              <li><strong>Bidirectional</strong> ‚Äî sees all tokens at once</li>
              <li><strong>Full Attention Mask</strong> ‚Äî complete visibility</li>
              <li><strong>Encoder-Only</strong> ‚Äî no decoder</li>
              <li><strong>Best for:</strong> Classification, understanding</li>
              <li><strong>Input:</strong> Raw text</li>
              <li><strong>Output:</strong> Embeddings, class labels</li>
            </ul>
          </div>
          <div id="gptCard" class="comparison-card">
            <h3>GPT</h3>
            <ul>
              <li><strong>Unidirectional</strong> ‚Äî left-to-right only</li>
              <li><strong>Causal Attention Mask</strong> ‚Äî triangular, can't see future</li>
              <li><strong>Decoder-Only</strong> ‚Äî no encoder</li>
              <li><strong>Best for:</strong> Text generation, completion</li>
              <li><strong>Input:</strong> Prompt + learned embeddings</li>
              <li><strong>Output:</strong> Next token probability</li>
            </ul>
          </div>
        </div>

        <h3 style="margin-top: 2rem; color: #00d2ff;">Attention Mask Visualization</h3>
        <div class="svg-container">
          <svg viewBox="0 0 600 280" xmlns="http://www.w3.org/2000/svg">
            <!-- BERT Full Mask -->
            <g id="bertMask">
              <text x="80" y="30" fill="#00d2ff" font-size="14" font-weight="500">BERT: Full Attention</text>
              <g transform="translate(20, 50)">
                <rect width="120" height="120" fill="none" stroke="#2a2a3e" stroke-width="1"/>
                <!-- Full square (all attention) -->
                <rect width="120" height="120" fill="url(#attentionGradient)" opacity="0.6"/>
                <text x="60" y="135" text-anchor="middle" fill="#8888a0" font-size="12">All tokens</text>
              </g>
            </g>

            <!-- GPT Causal Mask -->
            <g id="gptMask">
              <text x="360" y="30" fill="#00d2ff" font-size="14" font-weight="500">GPT: Causal Attention</text>
              <g transform="translate(300, 50)">
                <rect width="120" height="120" fill="none" stroke="#2a2a3e" stroke-width="1"/>
                <!-- Lower triangle (causal mask) -->
                <polygon points="0,0 120,0 120,120 0,120" fill="url(#attentionGradient)" opacity="0.6"/>
                <polygon points="0,0 120,120 0,120" fill="#0a0a0f" opacity="0.8"/>
                <text x="40" y="100" text-anchor="middle" fill="#ff6b6b" font-size="12">Can't attend</text>
              </g>
            </g>

            <!-- Gradients -->
            <defs>
              <linearGradient id="attentionGradient" x1="0%" y1="0%" x2="100%" y2="100%">
                <stop offset="0%" style="stop-color:#6c63ff;stop-opacity:1" />
                <stop offset="100%" style="stop-color:#00d2ff;stop-opacity:1" />
              </linearGradient>
            </defs>
          </svg>
        </div>
        <p style="text-align: center; color: #8888a0; margin-top: 1rem; font-size: 0.9rem;">
          BERT can see all tokens simultaneously. GPT can only attend to tokens that came before it (causal mask).
        </p>
      </div>
    </section>

    <!-- Autoregressive Generation Demo -->
    <section>
      <h2>üîÆ Autoregressive Generation: The Showpiece</h2>
      <div class="section-card">
        <p style="margin-bottom: 1.5rem;">
          This is how GPT actually generates text: <strong>one token at a time</strong>, predicting the probability distribution of the next token based on everything that came before.
        </p>

        <div class="demo-container">
          <div>
            <label style="color: #8888a0; font-size: 0.9rem;">üìù Generated Text:</label>
            <div class="prompt-display" id="generatedText">The ancient temple was</div>
          </div>

          <div>
            <label style="color: #8888a0; font-size: 0.9rem; display: block; margin-bottom: 0.5rem;">üéØ Next Token Probability Distribution (Top 10):</label>
            <div class="chart-container">
              <div class="bar-chart" id="tokenChart">
                <!-- Bars will be generated by JS -->
              </div>
            </div>
          </div>

          <div style="margin-top: 2rem;">
            <p style="color: #8888a0; font-size: 0.9rem; margin-bottom: 1rem;">Click a token to select it and continue generation:</p>
            <div class="tokens-grid" id="tokenButtons">
              <!-- Token buttons will be generated by JS -->
            </div>
          </div>

          <div style="margin-top: 1.5rem; display: flex; gap: 1rem;">
            <button class="toggle-btn" onclick="resetAutoregressive()">Reset</button>
            <button class="toggle-btn secondary" onclick="randomToken()" style="background: #2a2a3e; color: #d0d0d8;">Random Token</button>
          </div>

          <div class="status" id="generationStatus">
            Generation step: 0 / 5 (sample demonstrations)
          </div>
        </div>
      </div>
    </section>

    <!-- Temperature & Sampling Section -->
    <section>
      <h2>üå°Ô∏è Temperature & Sampling</h2>
      <div class="section-card">
        <p>
          Even with the same probability distribution, we can sample differently. <strong>Temperature</strong> controls how "sharp" or "flat" the distribution becomes.
        </p>

        <div class="demo-container">
          <div class="slider-group">
            <label>Temperature: <span id="tempValue">1.0</span></label>
            <input type="range" min="0.1" max="2.0" step="0.1" value="1.0" id="temperatureSlider"
                   oninput="updateTemperature(this.value)">
            <div style="font-size: 0.8rem; color: #8888a0; margin-top: 0.5rem;">
              0.1 = <span style="color: #ff6b6b;">deterministic</span> | 1.0 = <span style="color: #6c63ff;">balanced</span> | 2.0 = <span style="color: #00d2ff;">creative</span>
            </div>
          </div>

          <div class="sampling-toggles" style="margin-top: 2rem;">
            <label style="display: flex; align-items: center; gap: 0.5rem; color: #8888a0; font-size: 0.9rem;">
              <input type="checkbox" id="topKToggle" onchange="updateSampling()">
              <span>Top-K Sampling (K=5)</span>
            </label>
            <label style="display: flex; align-items: center; gap: 0.5rem; color: #8888a0; font-size: 0.9rem;">
              <input type="checkbox" id="topPToggle" onchange="updateSampling()">
              <span>Top-P Nucleus (P=0.9)</span>
            </label>
          </div>

          <div class="chart-container" style="margin-top: 1.5rem;">
            <label style="color: #8888a0; font-size: 0.9rem; display: block; margin-bottom: 1rem;">Temperature-adjusted distribution:</label>
            <div class="bar-chart" id="tempChart">
              <!-- Will be generated by JS -->
            </div>
          </div>

          <div style="margin-top: 1.5rem; padding: 1rem; background: #0a0a0f; border-radius: 4px; border-left: 3px solid #6c63ff;">
            <p style="font-size: 0.9rem;">
              <strong>Low Temperature (0.1):</strong> Model repeats safe tokens. Good for factual tasks.<br>
              <strong>High Temperature (2.0):</strong> Model explores diverse tokens. Good for creative writing.<br>
              <strong>Top-K & Top-P:</strong> Only sample from the most likely tokens, preventing extremely low-probability nonsense.
            </p>
          </div>
        </div>
      </div>
    </section>

    <!-- GPT Architecture Section -->
    <section>
      <h2>üèóÔ∏è The GPT Architecture</h2>
      <div class="section-card">
        <p>
          GPT is a <strong>decoder-only transformer</strong>. Unlike BERT (encoder-only) or seq2seq models (encoder + decoder), GPT has only the decoding stack.
        </p>

        <div class="arch-flow">
          <div class="arch-box" style="flex: 1; min-width: 150px;">
            <strong style="color: #00d2ff;">Input</strong><br>
            Tokens ‚Üí Embeddings + Positional Encoding
          </div>
          <div class="arrow">‚Üí</div>
          <div class="arch-box" style="flex: 1; min-width: 150px;">
            <strong style="color: #00d2ff;">N Decoder Layers</strong><br>
            Masked Self-Attn + FFN (√óN)
          </div>
          <div class="arrow">‚Üí</div>
          <div class="arch-box" style="flex: 1; min-width: 150px;">
            <strong style="color: #00d2ff;">Output</strong><br>
            Linear + Softmax ‚Üí Token Probs
          </div>
        </div>

        <h3 style="color: #00d2ff; margin-top: 1.5rem; margin-bottom: 1rem;">Key Points:</h3>
        <ul style="list-style-position: inside; color: #d0d0d8;">
          <li><strong>No Encoder:</strong> GPT learns to process input in a single pass</li>
          <li><strong>No Cross-Attention:</strong> Can't attend to a separate context like seq2seq</li>
          <li><strong>Causal Self-Attention:</strong> Each token only attends to previous tokens</li>
          <li><strong>Parameter Efficiency:</strong> Simpler than encoder-decoder, but scales to 175B+ parameters</li>
        </ul>

        <div class="svg-container" style="margin-top: 1.5rem;">
          <svg viewBox="0 0 800 400" xmlns="http://www.w3.org/2000/svg">
            <!-- Title -->
            <text x="400" y="30" text-anchor="middle" fill="#00d2ff" font-size="16" font-weight="500">Decoder-Only Transformer Stack</text>

            <!-- Input Layer -->
            <g id="inputLayer">
              <rect x="50" y="70" width="120" height="50" fill="#1a1a2e" stroke="#6c63ff" stroke-width="2" rx="4"/>
              <text x="110" y="102" text-anchor="middle" fill="#e0e0e8" font-size="12" font-weight="500">Token Embedding</text>
              <text x="110" y="120" text-anchor="middle" fill="#e0e0e8" font-size="12" font-weight="500">+ Positional Enc</text>
            </g>

            <!-- Decoder Layers -->
            <g id="decoderLayers">
              <!-- Layer 1 -->
              <g transform="translate(200, 70)">
                <rect width="110" height="50" fill="#1a1a2e" stroke="#00d2ff" stroke-width="2" rx="4"/>
                <text x="55" y="95" text-anchor="middle" fill="#e0e0e8" font-size="11" font-weight="500">Decoder Layer 1</text>
                <text x="55" y="110" text-anchor="middle" fill="#8888a0" font-size="9">(Masked Attn + FFN)</text>
              </g>

              <!-- ... indicator -->
              <text x="350" y="102" text-anchor="middle" fill="#8888a0" font-size="14" font-weight="bold">‚ãØ</text>

              <!-- Layer N -->
              <g transform="translate(400, 70)">
                <rect width="110" height="50" fill="#1a1a2e" stroke="#00d2ff" stroke-width="2" rx="4"/>
                <text x="55" y="95" text-anchor="middle" fill="#e0e0e8" font-size="11" font-weight="500">Decoder Layer N</text>
                <text x="55" y="110" text-anchor="middle" fill="#8888a0" font-size="9">(Masked Attn + FFN)</text>
              </g>
            </g>

            <!-- Output Layer -->
            <g id="outputLayer">
              <rect x="580" y="70" width="120" height="50" fill="#1a1a2e" stroke="#ff6b6b" stroke-width="2" rx="4"/>
              <text x="640" y="95" text-anchor="middle" fill="#e0e0e8" font-size="12" font-weight="500">Linear + Softmax</text>
              <text x="640" y="115" text-anchor="middle" fill="#8888a0" font-size="9">Vocab Probs</text>
            </g>

            <!-- Arrows -->
            <line x1="170" y1="95" x2="200" y2="95" stroke="#2a2a3e" stroke-width="2" marker-end="url(#arrowhead)"/>
            <line x1="310" y1="95" x2="350" y2="95" stroke="#2a2a3e" stroke-width="2" marker-end="url(#arrowhead)"/>
            <line x1="380" y1="95" x2="400" y2="95" stroke="#2a2a3e" stroke-width="2" marker-end="url(#arrowhead)"/>
            <line x1="510" y1="95" x2="580" y2="95" stroke="#2a2a3e" stroke-width="2" marker-end="url(#arrowhead)"/>

            <!-- Causal Mask Example -->
            <text x="400" y="180" text-anchor="middle" fill="#00d2ff" font-size="14" font-weight="500">Causal Attention Mask Example</text>

            <!-- Tokens row -->
            <text x="100" y="220" fill="#8888a0" font-size="11">Tokens:</text>
            <text x="150" y="220" fill="#d0d0d8" font-size="11">ancient</text>
            <text x="230" y="220" fill="#d0d0d8" font-size="11">temple</text>
            <text x="290" y="220" fill="#d0d0d8" font-size="11">was</text>
            <text x="340" y="220" fill="#d0d0d8" font-size="11">build</text>

            <!-- Mask matrix -->
            <g id="maskMatrix" transform="translate(100, 240)">
              <!-- Row 1 (attending to "ancient") -->
              <rect x="0" y="0" width="20" height="20" fill="#6c63ff" opacity="0.7"/>
              <rect x="20" y="0" width="20" height="20" fill="#0a0a0f" opacity="0.9" stroke="#2a2a3e" stroke-width="1"/>
              <rect x="40" y="0" width="20" height="20" fill="#0a0a0f" opacity="0.9" stroke="#2a2a3e" stroke-width="1"/>
              <rect x="60" y="0" width="20" height="20" fill="#0a0a0f" opacity="0.9" stroke="#2a2a3e" stroke-width="1"/>

              <!-- Row 2 (attending to "ancient", "temple") -->
              <rect x="0" y="20" width="20" height="20" fill="#6c63ff" opacity="0.7"/>
              <rect x="20" y="20" width="20" height="20" fill="#6c63ff" opacity="0.7"/>
              <rect x="40" y="20" width="20" height="20" fill="#0a0a0f" opacity="0.9" stroke="#2a2a3e" stroke-width="1"/>
              <rect x="60" y="20" width="20" height="20" fill="#0a0a0f" opacity="0.9" stroke="#2a2a3e" stroke-width="1"/>

              <!-- Row 3 (attending to "ancient", "temple", "was") -->
              <rect x="0" y="40" width="20" height="20" fill="#6c63ff" opacity="0.7"/>
              <rect x="20" y="40" width="20" height="20" fill="#6c63ff" opacity="0.7"/>
              <rect x="40" y="40" width="20" height="20" fill="#6c63ff" opacity="0.7"/>
              <rect x="60" y="40" width="20" height="20" fill="#0a0a0f" opacity="0.9" stroke="#2a2a3e" stroke-width="1"/>

              <!-- Row 4 (attending to all previous) -->
              <rect x="0" y="60" width="20" height="20" fill="#6c63ff" opacity="0.7"/>
              <rect x="20" y="60" width="20" height="20" fill="#6c63ff" opacity="0.7"/>
              <rect x="40" y="60" width="20" height="20" fill="#6c63ff" opacity="0.7"/>
              <rect x="60" y="60" width="20" height="20" fill="#6c63ff" opacity="0.7"/>

              <text x="100" y="60" fill="#8888a0" font-size="10">‚úì Can attend</text>
              <text x="100" y="80" fill="#8888a0" font-size="10">‚úó Masked out</text>
            </g>

            <defs>
              <marker id="arrowhead" markerWidth="10" markerHeight="10" refX="9" refY="3" orient="auto">
                <polygon points="0 0, 10 3, 0 6" fill="#2a2a3e"/>
              </marker>
            </defs>
          </svg>
        </div>
      </div>
    </section>

    <!-- Scaling Laws Section -->
    <section>
      <h2>üìà Scaling Laws</h2>
      <div class="section-card">
        <p>
          One of the most important discoveries from OpenAI's research: <strong>loss decreases predictably as we scale up model size, data, and compute.</strong> This enables scaling recipes like "Chinchilla" scaling.
        </p>

        <div class="scaling-controls">
          <div class="slider-group">
            <label>Model Parameters: <span id="paramValue">117M</span></label>
            <input type="range" min="0" max="100" value="0" id="paramSlider" oninput="updateScaling()">
            <div style="font-size: 0.75rem; color: #8888a0;">GPT-1 (117M) ‚Üí GPT-4 (1.8T)</div>
          </div>
          <div class="slider-group">
            <label>Training Tokens: <span id="dataValue">1B</span></label>
            <input type="range" min="0" max="100" value="0" id="dataSlider" oninput="updateScaling()">
            <div style="font-size: 0.75rem; color: #8888a0;">1B ‚Üí 13T tokens</div>
          </div>
          <div class="slider-group">
            <label>Compute (FLOPs): <span id="computeValue">1e18</span></label>
            <input type="range" min="0" max="100" value="0" id="computeSlider" oninput="updateScaling()">
            <div style="font-size: 0.75rem; color: #8888a0;">1e18 ‚Üí 5e24</div>
          </div>
        </div>

        <div class="svg-container">
          <svg viewBox="0 0 700 400" xmlns="http://www.w3.org/2000/svg">
            <!-- Title -->
            <text x="350" y="25" text-anchor="middle" fill="#00d2ff" font-size="14" font-weight="500">Loss vs. Model Size (log-log scale)</text>

            <!-- Axes -->
            <line x1="80" y1="350" x2="650" y2="350" stroke="#2a2a3e" stroke-width="2"/>
            <line x1="80" y1="350" x2="80" y2="50" stroke="#2a2a3e" stroke-width="2"/>

            <!-- Axis labels -->
            <text x="380" y="380" text-anchor="middle" fill="#8888a0" font-size="12">Model Parameters (log scale)</text>
            <text x="30" y="200" text-anchor="middle" fill="#8888a0" font-size="12" transform="rotate(-90 30 200)">Loss (log scale)</text>

            <!-- Grid lines -->
            <line x1="150" y1="350" x2="150" y2="345" stroke="#2a2a3e" stroke-width="1"/>
            <line x1="250" y1="350" x2="250" y2="345" stroke="#2a2a3e" stroke-width="1"/>
            <line x1="350" y1="350" x2="350" y2="345" stroke="#2a2a3e" stroke-width="1"/>
            <line x1="450" y1="350" x2="450" y2="345" stroke="#2a2a3e" stroke-width="1"/>
            <line x1="550" y1="350" x2="550" y2="345" stroke="#2a2a3e" stroke-width="1"/>
            <line x1="650" y1="350" x2="650" y2="345" stroke="#2a2a3e" stroke-width="1"/>

            <line x1="75" y1="320" x2="80" y2="320" stroke="#2a2a3e" stroke-width="1"/>
            <line x1="75" y1="260" x2="80" y2="260" stroke="#2a2a3e" stroke-width="1"/>
            <line x1="75" y1="200" x2="80" y2="200" stroke="#2a2a3e" stroke-width="1"/>
            <line x1="75" y1="140" x2="80" y2="140" stroke="#2a2a3e" stroke-width="1"/>
            <line x1="75" y1="80" x2="80" y2="80" stroke="#2a2a3e" stroke-width="1"/>

            <!-- Axis tick labels -->
            <text x="150" y="368" text-anchor="middle" fill="#8888a0" font-size="10">1M</text>
            <text x="250" y="368" text-anchor="middle" fill="#8888a0" font-size="10">10M</text>
            <text x="350" y="368" text-anchor="middle" fill="#8888a0" font-size="10">100M</text>
            <text x="450" y="368" text-anchor="middle" fill="#8888a0" font-size="10">1B</text>
            <text x="550" y="368" text-anchor="middle" fill="#8888a0" font-size="10">10B</text>
            <text x="650" y="368" text-anchor="middle" fill="#8888a0" font-size="10">100B+</text>

            <text x="70" y="325" text-anchor="end" fill="#8888a0" font-size="10">5.0</text>
            <text x="70" y="265" text-anchor="end" fill="#8888a0" font-size="10">4.0</text>
            <text x="70" y="205" text-anchor="end" fill="#8888a0" font-size="10">3.0</text>
            <text x="70" y="145" text-anchor="end" fill="#8888a0" font-size="10">2.0</text>
            <text x="70" y="85" text-anchor="end" fill="#8888a0" font-size="10">1.0</text>

            <!-- Scaling law curve -->
            <path id="scalingCurve" d="M 100 310 Q 250 240 400 140 T 640 80"
                  fill="none" stroke="#6c63ff" stroke-width="2.5" stroke-dasharray="5,5" opacity="0.8"/>

            <!-- Data points -->
            <circle cx="130" cy="305" r="5" fill="#ff6b6b"/>
            <text x="130" y="325" text-anchor="middle" fill="#ff6b6b" font-size="10" font-weight="500">GPT-1</text>

            <circle cx="240" cy="245" r="5" fill="#00d2ff"/>
            <text x="240" y="265" text-anchor="middle" fill="#00d2ff" font-size="10" font-weight="500">GPT-2</text>

            <circle cx="380" cy="155" r="5" fill="#6c63ff"/>
            <text x="380" y="175" text-anchor="middle" fill="#6c63ff" font-size="10" font-weight="500">GPT-3</text>

            <circle cx="520" cy="95" r="5" fill="#6bcf7f"/>
            <text x="520" y="75" text-anchor="middle" fill="#6bcf7f" font-size="10" font-weight="500">GPT-4</text>

            <!-- Legend -->
            <text x="100" y="40" fill="#8888a0" font-size="11">Predicted trend from scaling laws</text>
            <line x1="100" y1="35" x2="130" y2="35" stroke="#6c63ff" stroke-width="2" stroke-dasharray="5,5"/>
          </svg>
        </div>

        <h3 style="color: #00d2ff; margin-top: 1.5rem; margin-bottom: 1rem;">Key Findings:</h3>
        <table>
          <thead>
            <tr>
              <th>Model</th>
              <th>Parameters</th>
              <th>Training Tokens</th>
              <th>Key Insight</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td><strong>GPT-1</strong></td>
              <td>117M</td>
              <td>~1B</td>
              <td>Proof that transformer LMs can learn language via unsupervised pretraining</td>
            </tr>
            <tr>
              <td><strong>GPT-2</strong></td>
              <td>1.5B</td>
              <td>~40B</td>
              <td>Zero-shot capabilities emerge. Impressive text quality even without fine-tuning.</td>
            </tr>
            <tr>
              <td><strong>GPT-3</strong></td>
              <td>175B</td>
              <td>~300B</td>
              <td>In-context learning. Can learn tasks from few examples in the prompt.</td>
            </tr>
            <tr>
              <td><strong>Scaling Laws</strong></td>
              <td colspan="3">Loss ‚àù N^(-Œ±), where N = parameters. Simple formula predicts compute needed for a target loss.</td>
            </tr>
          </tbody>
        </table>

        <div style="margin-top: 1.5rem; padding: 1rem; background: #0a0a0f; border-radius: 4px; border-left: 3px solid #6c63ff;">
          <strong style="color: #00d2ff;">Chinchilla Scaling:</strong> Optimal balance between model size and training data. Modern LLMs use roughly equal FLOPs on parameters and data (not 10:1 ratio like earlier models).
        </div>
      </div>
    </section>

    <!-- In-Context Learning Section -->
    <section>
      <h2>üß† In-Context Learning (Few-Shot)</h2>
      <div class="section-card">
        <p>
          GPT-3 made a surprising discovery: <strong>large language models can learn new tasks from examples in the prompt alone, without any fine-tuning.</strong> This is in-context learning.
        </p>

        <div class="demo-container">
          <label style="color: #8888a0; font-size: 0.9rem; display: block; margin-bottom: 1rem;">
            Number of Examples:
            <span id="shotCount">3</span>-shot
          </label>
          <input type="range" min="0" max="3" value="3" id="shotSlider" oninput="updateFewShot(this.value)">

          <div style="margin-top: 2rem;">
            <h3 style="color: #00d2ff; font-size: 1.1rem; margin-bottom: 1rem;">Sentiment Analysis Example</h3>

            <div id="fewShotExamples">
              <!-- Examples will be inserted here by JS -->
            </div>

            <div class="example-card input" style="margin-top: 1.5rem;">
              <div class="example-label">New Input</div>
              <p>"The movie was absolutely brilliant and moving. Highly recommended!"</p>
            </div>

            <div class="example-card output">
              <div class="example-label">Model Prediction</div>
              <p><strong style="color: #6bcf7f;">Positive</strong> (confidence: 0.94)</p>
            </div>
          </div>

          <div style="margin-top: 1.5rem; padding: 1rem; background: #0a0a0f; border-radius: 4px; border-left: 3px solid #6c63ff;">
            <p style="font-size: 0.9rem;">
              <strong>Zero-shot:</strong> "Is this positive or negative?" + input<br>
              <strong>Few-shot:</strong> Example 1, Example 2, ..., then input<br>
              <strong>Insight:</strong> More examples ‚âà better performance (up to a point)
            </p>
          </div>
        </div>
      </div>
    </section>

    <!-- From GPT to ChatGPT -->
    <section>
      <h2>üí¨ From GPT to ChatGPT: Alignment</h2>
      <div class="section-card">
        <p>
          Raw GPT models are good at text completion, but not ideal as assistants. ChatGPT adds two crucial steps to transform GPT into a helpful, safe chatbot.
        </p>

        <div class="svg-container">
          <svg viewBox="0 0 800 300" xmlns="http://www.w3.org/2000/svg">
            <!-- Title -->
            <text x="400" y="30" text-anchor="middle" fill="#00d2ff" font-size="14" font-weight="500">From GPT-3 to ChatGPT: The Alignment Pipeline</text>

            <!-- Stage 1: Pre-training -->
            <g transform="translate(50, 80)">
              <rect width="150" height="100" fill="#1a1a2e" stroke="#6c63ff" stroke-width="2" rx="4"/>
              <text x="75" y="35" text-anchor="middle" fill="#00d2ff" font-size="13" font-weight="500">Stage 1: Pre-training</text>
              <text x="75" y="60" text-anchor="middle" fill="#d0d0d8" font-size="11">Train on 300B tokens</text>
              <text x="75" y="78" text-anchor="middle" fill="#d0d0d8" font-size="11">Learn language patterns</text>
              <text x="75" y="96" text-anchor="middle" fill="#d0d0d8" font-size="11">Predict next token</text>
            </g>

            <!-- Arrow -->
            <line x1="210" y1="130" x2="250" y2="130" stroke="#2a2a3e" stroke-width="2" marker-end="url(#arrowhead2)"/>

            <!-- Stage 2: SFT -->
            <g transform="translate(270, 80)">
              <rect width="150" height="100" fill="#1a1a2e" stroke="#00d2ff" stroke-width="2" rx="4"/>
              <text x="75" y="35" text-anchor="middle" fill="#00d2ff" font-size="13" font-weight="500">Stage 2: SFT</text>
              <text x="75" y="60" text-anchor="middle" fill="#d0d0d8" font-size="11">Supervised Fine-Tuning</text>
              <text x="75" y="78" text-anchor="middle" fill="#d0d0d8" font-size="11">Human-written Q&A</text>
              <text x="75" y="96" text-anchor="middle" fill="#d0d0d8" font-size="11">Learn assistant behavior</text>
            </g>

            <!-- Arrow -->
            <line x1="430" y1="130" x2="470" y2="130" stroke="#2a2a3e" stroke-width="2" marker-end="url(#arrowhead2)"/>

            <!-- Stage 3: RLHF -->
            <g transform="translate(490, 80)">
              <rect width="150" height="100" fill="#1a1a2e" stroke="#ff6b6b" stroke-width="2" rx="4"/>
              <text x="75" y="35" text-anchor="middle" fill="#00d2ff" font-size="13" font-weight="500">Stage 3: RLHF</text>
              <text x="75" y="60" text-anchor="middle" fill="#d0d0d8" font-size="11">Reinforcement Learning</text>
              <text x="75" y="78" text-anchor="middle" fill="#d0d0d8" font-size="11">from Human Feedback</text>
              <text x="75" y="96" text-anchor="middle" fill="#d0d0d8" font-size="11">Learn human preferences</text>
            </g>

            <!-- Result -->
            <text x="400" y="240" text-anchor="middle" fill="#6bcf7f" font-size="12" font-weight="500">‚Üí ChatGPT: Safe, helpful, honest</text>

            <!-- Descriptions -->
            <text x="50" y="270" fill="#8888a0" font-size="10">Unsupervised learning on internet text</text>
            <text x="270" y="270" fill="#8888a0" font-size="10">Labeled by humans</text>
            <text x="510" y="270" fill="#8888a0" font-size="10">Optimize for human ratings</text>

            <defs>
              <marker id="arrowhead2" markerWidth="10" markerHeight="10" refX="9" refY="3" orient="auto">
                <polygon points="0 0, 10 3, 0 6" fill="#2a2a3e"/>
              </marker>
            </defs>
          </svg>
        </div>

        <h3 style="color: #00d2ff; margin-top: 2rem; margin-bottom: 1rem;">Why Each Stage Matters:</h3>
        <ul style="list-style-position: inside; color: #d0d0d8;">
          <li><strong>Pre-training:</strong> Learn language at scale. Expensive, done once.</li>
          <li><strong>SFT:</strong> Teach the model to follow instructions and act like an assistant. Faster than pre-training.</li>
          <li><strong>RLHF:</strong> Align the model with human values. Penalize harmful outputs, reward helpful ones.</li>
        </ul>
      </div>
    </section>

    <!-- Python Code Section -->
    <section>
      <h2>üíª Code: Text Generation with GPT-2</h2>
      <div class="section-card">
        <p>Here's how to load and use GPT-2 in HuggingFace Transformers:</p>

        <div class="code-block">
          <pre><span class="token-comment"># Load GPT-2 from HuggingFace</span>
<span class="token-keyword">from</span> transformers <span class="token-keyword">import</span> GPT2Tokenizer, GPT2LMHeadModel

tokenizer = GPT2Tokenizer.from_pretrained(<span class="token-string">"gpt2"</span>)
model = GPT2LMHeadModel.from_pretrained(<span class="token-string">"gpt2"</span>)

<span class="token-comment"># Generate text with different temperatures</span>
<span class="token-keyword">def</span> <span class="token-function">generate_text</span>(prompt, temperature=<span class="token-number">1.0</span>, max_length=<span class="token-number">50</span>):
    input_ids = tokenizer.encode(prompt, return_tensors=<span class="token-string">"pt"</span>)

    output = model.generate(
        input_ids,
        max_length=max_length,
        temperature=temperature,
        top_p=<span class="token-number">0.95</span>,  <span class="token-comment"># nucleus sampling</span>
        do_sample=<span class="token-keyword">True</span>
    )

    <span class="token-keyword">return</span> tokenizer.decode(output[<span class="token-number">0</span>], skip_special_tokens=<span class="token-keyword">True</span>)

<span class="token-comment"># Low temperature: deterministic</span>
deterministic = generate_text(<span class="token-string">"The ancient temple was"</span>, temperature=<span class="token-number">0.2</span>)

<span class="token-comment"># High temperature: creative</span>
creative = generate_text(<span class="token-string">"The ancient temple was"</span>, temperature=<span class="token-number">1.5</span>)

<span class="token-comment"># Few-shot learning</span>
few_shot_prompt = <span class="token-string">"""
Example 1: "Great movie!" ‚Üí Positive
Example 2: "Terrible experience." ‚Üí Negative
Example 3: "It's okay." ‚Üí Neutral
New: "Absolutely wonderful!" ‚Üí
"""</span>

prediction = generate_text(few_shot_prompt, max_length=<span class="token-number">5</span>)

<span class="token-comment"># Compute perplexity (how surprised the model is by the data)</span>
<span class="token-keyword">import</span> torch

text = <span class="token-string">"The ancient temple stood for centuries."</span>
input_ids = tokenizer.encode(text, return_tensors=<span class="token-string">"pt"</span>)

<span class="token-keyword">with</span> torch.no_grad():
    outputs = model(input_ids, labels=input_ids)
    loss = outputs.loss
    perplexity = torch.exp(loss)

print(<span class="token-string">f"Perplexity: {perplexity:.2f}"</span>)</pre>
        </div>

        <div style="margin-top: 1rem; padding: 1rem; background: #0a0a0f; border-radius: 4px; border-left: 3px solid #6c63ff;">
          <p style="font-size: 0.9rem;">
            <strong>Perplexity:</strong> A metric of how well the model predicts the data. Lower is better. A perplexity of 2 means on average the model is surprised by a factor of 2.
          </p>
        </div>
      </div>
    </section>

    <!-- Translation Connection -->
    <section>
      <h2>üåç Translating with GPT: Ancient Language Tasks</h2>
      <div class="section-card">
        <p>
          While GPT is a <strong>decoder-only</strong> model designed for generation, it can handle translation tasks through clever prompting or fine-tuning. This bridges to our next module on specialized encoder-decoder architectures.
        </p>

        <h3 style="color: #00d2ff; margin: 1rem 0; font-size: 1.1rem;">Approach 1: Prompting (Zero-shot)</h3>
        <div class="example-card input">
          <div class="example-label">Prompt</div>
          <p>Translate the following Latin text to English: "Tempus fugit"</p>
        </div>
        <div class="example-card output">
          <div class="example-label">GPT Output</div>
          <p>"Time flies" ‚Äî Correct! (via in-context learning)</p>
        </div>

        <h3 style="color: #00d2ff; margin: 1rem 0; font-size: 1.1rem;">Approach 2: Fine-tuning</h3>
        <p>Fine-tune GPT on pairs of (Ancient Language, Modern Translation) to specialize in ancient language tasks:</p>
        <div class="example-card">
          <div class="example-label">Training Data</div>
          <code style="color: #00d2ff;">{"input": "Salve, amice", "output": "Hello, friend"}</code>
        </div>

        <h3 style="color: #00d2ff; margin: 1rem 0; font-size: 1.1rem;">Why This Matters</h3>
        <ul style="list-style-position: inside; color: #d0d0d8;">
          <li>GPT can be adapted to nearly any task via prompting or fine-tuning</li>
          <li>But <strong>encoder-decoder models</strong> (next module) are often better for specific translation tasks</li>
          <li>Modern systems combine both: GPT for generation, specialized models for translation</li>
        </ul>
      </div>
    </section>

    <!-- Footer Navigation -->
    <footer>
      <a href="07-bert.html">‚Üê BERT: Bidirectional Encoders</a>
      <a href="09-finetuning.html">Fine-Tuning & Alignment ‚Üí</a>
    </footer>
  </div>

  <script>
    // Data for autoregressive generation demo
    const tokenSequences = [
      {
        tokens: ['made', 'built', 'carved', 'stood', 'held'],
        probs: [0.35, 0.28, 0.15, 0.12, 0.10]
      },
      {
        tokens: ['by', 'of', 'with', 'through', 'during'],
        probs: [0.32, 0.25, 0.18, 0.14, 0.11]
      },
      {
        tokens: ['ancient', 'skilled', 'master', 'powerful', 'unknown'],
        probs: [0.28, 0.22, 0.18, 0.16, 0.16]
      },
      {
        tokens: ['architects', 'builders', 'priests', 'kings', 'civilizations'],
        probs: [0.31, 0.26, 0.18, 0.14, 0.11]
      },
      {
        tokens: ['.', 'in', 'over', 'for', 'and'],
        probs: [0.25, 0.22, 0.18, 0.18, 0.17]
      }
    ];

    let currentStep = 0;
    let generatedText = 'The ancient temple was';

    function initializeAutoregressive() {
      updateTokenChart();
    }

    function updateTokenChart() {
      const container = document.getElementById('tokenChart');
      container.innerHTML = '';

      if (currentStep >= tokenSequences.length) {
        container.innerHTML = '<p style="color: #8888a0; text-align: center;">Generation complete!</p>';
        return;
      }

      const { tokens, probs } = tokenSequences[currentStep];

      tokens.forEach((token, idx) => {
        const bar = document.createElement('div');
        bar.className = 'bar';

        const height = probs[idx] * 100;
        bar.style.height = (height + 20) + 'px';

        const label = document.createElement('div');
        label.className = 'bar-label';
        label.textContent = token.slice(0, 6);

        const value = document.createElement('div');
        value.className = 'bar-value';
        value.textContent = (probs[idx] * 100).toFixed(0) + '%';

        bar.appendChild(label);
        bar.appendChild(value);
        container.appendChild(bar);
      });

      updateTokenButtons();
    }

    function updateTokenButtons() {
      const container = document.getElementById('tokenButtons');
      container.innerHTML = '';

      if (currentStep >= tokenSequences.length) return;

      const { tokens, probs } = tokenSequences[currentStep];

      tokens.forEach((token, idx) => {
        const btn = document.createElement('button');
        btn.className = 'token-btn';
        btn.innerHTML = `${token}<span class="prob">${(probs[idx] * 100).toFixed(0)}%</span>`;
        btn.onclick = () => selectToken(token);
        container.appendChild(btn);
      });
    }

    function selectToken(token) {
      if (currentStep >= tokenSequences.length) return;

      generatedText += ' ' + token;
      currentStep++;

      document.getElementById('generatedText').textContent = generatedText;
      document.getElementById('generationStatus').textContent =
        `Generation step: ${currentStep} / 5 (sample demonstrations)`;

      updateTokenChart();
    }

    function randomToken() {
      if (currentStep >= tokenSequences.length) return;

      const { tokens, probs } = tokenSequences[currentStep];
      const idx = Math.floor(Math.random() * tokens.length);
      selectToken(tokens[idx]);
    }

    function resetAutoregressive() {
      currentStep = 0;
      generatedText = 'The ancient temple was';
      document.getElementById('generatedText').textContent = generatedText;
      document.getElementById('generationStatus').textContent = 'Generation step: 0 / 5 (sample demonstrations)';
      updateTokenChart();
    }

    // Temperature and Sampling
    function updateTemperature(value) {
      const temp = parseFloat(value);
      document.getElementById('tempValue').textContent = temp.toFixed(1);
      updateTempChart();
    }

    function updateSampling() {
      updateTempChart();
    }

    function updateTempChart() {
      const temp = parseFloat(document.getElementById('temperatureSlider').value);
      const topK = document.getElementById('topKToggle').checked;
      const topP = document.getElementById('topPToggle').checked;

      const container = document.getElementById('tempChart');
      container.innerHTML = '';

      // Base probabilities
      const baseTokens = ['made', 'built', 'carved', 'stood', 'held', 'created', 'erected', 'formed', 'raised', 'shaped'];
      const baseProbs = [0.35, 0.28, 0.15, 0.12, 0.10, 0.04, 0.02, 0.01, 0.015, 0.01];

      // Apply temperature
      const logits = baseProbs.map(p => Math.log(p + 1e-10) / temp);
      const maxLogit = Math.max(...logits);
      const expLogits = logits.map(l => Math.exp(l - maxLogit));
      const sumExp = expLogits.reduce((a, b) => a + b, 0);
      let tempProbs = expLogits.map(e => e / sumExp);

      // Apply top-K
      if (topK) {
        const sorted = tempProbs.map((p, i) => ({ prob: p, idx: i })).sort((a, b) => b.prob - a.prob);
        tempProbs = tempProbs.map((p, i) => {
          const rank = sorted.findIndex(s => s.idx === i);
          return rank < 5 ? p : 0;
        });
        const newSum = tempProbs.reduce((a, b) => a + b, 0);
        tempProbs = tempProbs.map(p => p / newSum);
      }

      // Apply top-P
      if (topP) {
        const sorted = tempProbs.map((p, i) => ({ prob: p, idx: i })).sort((a, b) => b.prob - a.prob);
        let cumSum = 0;
        const mask = new Array(tempProbs.length).fill(false);
        for (const { prob, idx } of sorted) {
          cumSum += prob;
          mask[idx] = true;
          if (cumSum > 0.9) break;
        }
        tempProbs = tempProbs.map((p, i) => mask[i] ? p : 0);
        const newSum = tempProbs.reduce((a, b) => a + b, 0);
        tempProbs = tempProbs.map(p => p / newSum);
      }

      // Render bars
      baseTokens.forEach((token, idx) => {
        const bar = document.createElement('div');
        bar.className = 'bar';

        const height = Math.max(tempProbs[idx] * 150, 5);
        bar.style.height = height + 'px';

        const label = document.createElement('div');
        label.className = 'bar-label';
        label.textContent = token.slice(0, 6);

        const value = document.createElement('div');
        value.className = 'bar-value';
        value.textContent = (tempProbs[idx] * 100).toFixed(1) + '%';

        bar.appendChild(label);
        bar.appendChild(value);
        container.appendChild(bar);
      });
    }

    // Toggle Architecture View
    function toggleArchitecture() {
      const bertCard = document.getElementById('bertCard');
      const gptCard = document.getElementById('gptCard');

      bertCard.classList.toggle('active');
      gptCard.classList.toggle('active');
    }

    // Scaling Laws
    function updateScaling() {
      const paramSlider = parseFloat(document.getElementById('paramSlider').value);
      const dataSlider = parseFloat(document.getElementById('dataSlider').value);
      const computeSlider = parseFloat(document.getElementById('computeSlider').value);

      // Map slider values to actual scales (log scale)
      const params = Math.pow(10, 8 + (paramSlider / 100) * 3.25); // 117M to 1.8T
      const data = Math.pow(10, 9 + (dataSlider / 100) * 4.1); // 1B to 13T
      const compute = Math.pow(10, 18 + (computeSlider / 100) * 6.7); // 1e18 to 5e24

      document.getElementById('paramValue').textContent = formatNumber(params);
      document.getElementById('dataValue').textContent = formatNumber(data);
      document.getElementById('computeValue').textContent = formatScientific(compute);
    }

    function formatNumber(num) {
      if (num >= 1e12) return (num / 1e12).toFixed(1) + 'T';
      if (num >= 1e9) return (num / 1e9).toFixed(1) + 'B';
      if (num >= 1e6) return (num / 1e6).toFixed(1) + 'M';
      return num.toFixed(0);
    }

    function formatScientific(num) {
      return 'e' + Math.log10(num).toFixed(0);
    }

    // Few-shot Learning
    function updateFewShot(shots) {
      const container = document.getElementById('fewShotExamples');
      container.innerHTML = '';

      const examples = [
        { text: '"The movie was fantastic!"', label: 'Positive', emoji: 'üòä' },
        { text: '"Worst experience ever."', label: 'Negative', emoji: 'üòû' },
        { text: '"It was okay, nothing special."', label: 'Neutral', emoji: 'üòê' }
      ];

      const numShots = parseInt(shots);
      for (let i = 0; i < numShots; i++) {
        const ex = examples[i];
        const card = document.createElement('div');
        card.className = 'example-card';
        card.innerHTML = `
          <div class="example-label">Example ${i + 1}</div>
          <p>${ex.text}</p>
          <p style="margin-top: 0.5rem; color: #6bcf7f;">‚Üí <strong>${ex.label}</strong> ${ex.emoji}</p>
        `;
        container.appendChild(card);
      }

      document.getElementById('shotCount').textContent = numShots;
    }

    // Initialize on page load
    document.addEventListener('DOMContentLoaded', () => {
      initializeAutoregressive();
      updateTemperature(1.0);
      updateScaling();
      updateFewShot(3);
    });
  </script>
</body>
</html>
